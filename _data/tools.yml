################################################################################
# Data for the display on the detailed ecosystem pages
################################################################################
- name: Alluxio
  anchor: alluxio
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/alluxio.png
  logosmall: /assets/images/logos/alluxio-small.png
  description: |
    Alluxio provides a single pane of glass for enterprises to manage data and
    AI workloads across diverse infrastructure environments with ease. Alluxio
    Data Platform has two product offerings, Alluxio Enterprise Data and Alluxio
    Enterprise AI.

    Alluxio provides an open source object storage caching solution that is the
    base of the file system cache and the Alluxio file system support in Trino.
    The commercial platform with its distributed block-level read/write caching
    functionality can be used for further integration.
  links:
    - urltext: Alluxio
      url: https://www.alluxio.io/
    - urltext: Interactive analytics with Trino and Alluxio product information
      url: https://www.alluxio.io/trino/
    - urltext: Trino file system cache documentation
      url: /docs/current/object-storage/file-system-cache.html
    - urltext: Trino Alluxio file system support documentation
      url: /docs/current/object-storage/file-system-alluxio.html
    - urltext: Documentation for Alluxio platform with Trino
      url: https://docs.alluxio.io/ee/user/stable/en/compute/Trino.html
- name: Amazon Kinesis
  anchor: amazon-kinesis
  category: data-source
  owner: other
  logo: /assets/images/logos/amazon-kinesis.png
  logosmall: /assets/images/logos/amazon-kinesis-small.png
  description: |
    Note that the Kinesis connector is removed from Trino 470 and later, and no
    longer maintained. Users must retrieve and update the code from the source
    code repository, or use an old Trino version.

    Amazon Kinesis cost-effectively processes and analyzes streaming data at any
    scale as a fully managed service. With Kinesis, you can ingest real-time
    data, such as video, audio, application logs, website clickstreams, and IoT
    telemetry data, for machine learning (ML), analytics, and other
    applications.

    Use an Amazon Kinesis stream as a data source in Trino by configuring a
    catalog with the Kinesis connector.
  links:
    - urltext: Amazon Kinesis
      url: https://aws.amazon.com/kinesis/
    - urltext: Kinesis connector documentation
      url: /docs/469/connector/kinesis.html
- name: Amazon Redshift
  anchor: amazon-redshift
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/amazon-redshift.png
  logosmall: /assets/images/logos/amazon-redshift-small.png
  description: |
    Amazon Redshift uses SQL to analyze structured and semi-structured data
    across data warehouses, operational databases, and data lakes, using
    AWS-designed hardware and machine learning to deliver the best price
    performance at any scale.

    Use an Amazon Redshift data warehouse as a data source in Trino by
    configuring a catalog with the Redshift connector.
  links:
    - urltext: Amazon Redshift
      url: https://aws.amazon.com/redshift/
    - urltext: Redshift connector documentation
      url: /docs/current/connector/redshift.html
- name: Amazon S3
  anchor: amazon-s3
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/amazon-s3.png
  logosmall: /assets/images/logos/amazon-s3-small.png
  description: |
    Amazon Simple Storage Service (Amazon S3) is an object storage service
    offering industry-leading scalability, data availability, security, and
    performance. Millions of customers of all sizes and industries store,
    manage, analyze, and protect any amount of data for virtually any use case,
    such as data lakes, cloud-native applications, and mobile apps. With
    cost-effective storage classes and easy-to-use management features, you can
    optimize costs, organize and analyze data, and configure fine-tuned access
    controls to meet specific business and compliance requirements.

    Use the S3 file system support with the Delta Lake, Hive, Hudi or Iceberg
    connectors to access data in S3.
  links:
    - urltext: Amazon S3
      url: https://aws.amazon.com/s3/
    - urltext: S3 file system support documentation
      url: /docs/current/object-storage/file-system-s3.html
- name: Apache Accumulo
  anchor: apache-accumulo
  category: data-source
  owner: other
  logo: /assets/images/logos/apache-accumulo.png
  logosmall: /assets/images/logos/apache-accumulo-small.png
  description: |
    Note that the Accumulo connector is removed from Trino 464 and later, and no
    longer maintained. Users must retrieve and update the code from the source
    code repository, or use an old Trino version.

    Apache Accumulo® is a sorted, distributed key-value store that provides
    robust, scalable data storage and retrieval.

    Use an Apache Accumulo key-value store as a data source in Trino by
    configuring a catalog with the Accumulo connector.
  links:
    - urltext: Apache Accumulo
      url: https://accumulo.apache.org/
    - urltext: Legacy Accumulo connector documentation
      url: https://trino.io/docs/463/connector/accumulo.html
- name: Apache Airflow
  anchor: apache-airflow
  category: client-application
  owner: other
  logo: /assets/images/logos/airflow.png
  logosmall: /assets/images/logos/airflow-small.png
  description: |
    Airflow™ is a platform created by the community to programmatically author,
    schedule, and monitor workflows.
  links:
    - urltext: Apache Airflow
      url: https://airflow.apache.org/
    - urltext: Trino provider for Apache Airflow
      url: https://airflow.apache.org/docs/apache-airflow-providers-trino/stable/index.html
    - urltext: Using Trino with Apache Airflow for (almost) all your data
        problems from Trino Summit 2022
      url: /blog/2022/12/21/trino-summit-2022-astronomer-recap.html
- name: Apache Cassandra
  anchor: apache-cassandra
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-cassandra.png
  logosmall: /assets/images/logos/apache-cassandra-small.png
  description: |
    Apache Cassandra is an open source NoSQL distributed database trusted by
    thousands of companies for scalability and high availability without
    compromising performance. Linear scalability and proven fault-tolerance on
    commodity hardware or cloud infrastructure make it the perfect platform for
    mission-critical data.

    Use an Apache Cassandra database as a data source in Trino by configuring a
    catalog with the Cassandra connector.
  links:
    - urltext: Apache Cassandra
      url: https://cassandra.apache.org/
    - urltext: Cassandra connector documentation
      url: /docs/current/connector/cassandra.html
- name: Apache DolphinScheduler
  anchor: apache-dolphinscheduler
  category: client-application
  owner: other
  logo: /assets/images/logos/apache-dolphinscheduler.png
  logosmall: /assets/images/logos/apache-dolphinscheduler-small.png
  description: |
    Apache DolphinScheduler is an open-source, distributed workflow scheduling
    platform designed to manage and execute batch jobs, data pipelines, and ETL
    processes. DolphinScheduler enables users to create and manage consecutive
    jobs run easily, including support for different types of tasks, such as SQL
    statements, shell scripts, Spark jobs, Kubernetes deployments, and many
    others.
  links:
    - urltext: Apache DolphinScheduler
      url: https://dolphinscheduler.apache.org/
    - urltext: Trino swimming with the DolphinScheduler from Trino Community
        Broadcast 45
      url: /episodes/45.html
- name: Apache Druid
  anchor: apache-druid
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-druid.png
  logosmall: /assets/images/logos/apache-druid-small.png
  description: |
    Druid is a high performance, in-memory, real-time analytics database that
    delivers sub-second queries on streaming and batch data at scale and under
    load.

    Use an Apache Druid database as a data source in Trino by configuring a
    catalog with the Druid connector.
  links:
    - urltext: Apache Druid
      url: https://druid.apache.org/
    - urltext: Druid connector documentation
      url: /docs/current/connector/druid.html
    - urltext: Make data fluid with Apache Druid from Trino Community Broadcast
        16
      url: /episodes/16.html
- name: Apache Hive
  anchor: apache-hive
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-hive.png
  logosmall: /assets/images/logos/apache-hive-small.png
  description: |
    Apache Hive is a distributed, fault-tolerant data warehouse system that
    enables analytics at a massive scale and facilitates reading, writing, and
    managing petabytes of data residing in distributed storage using SQL. It is
    part of the larger Apache Hadoop project.

    Use an Apache Hive data warehouse as a data source in Trino by configuring a
    catalog with the Hive connector. Use the Hive metastore service as a
    metastore with the Delta Lake, Hive, Hudi, and Iceberg connectors. Use the
    Hadoop Distributed File System (HDFS) file system support as file system
    with the Delta Lake, Hive, Hudi, and Iceberg connectors.
  links:
    - urltext: Apache Hive
      url: https://hive.apache.org/
    - urltext: Apache Hadoop
      url: https://hadoop.apache.org/
    - urltext: Hive connector documentation
      url: /docs/current/connector/hive.html
    - urltext: Hive Thrift metastore documentation
      url: /docs/current/object-storage/metastores.html
    - urltext: HDFS file system support
      url: /docs/current/object-storage/file-system-hdfs.html
    - urltext: What is Trino and the Hive connector from Trino Community
        Broadcast 29
      url: /episodes/29.html
- name: Apache Hudi
  anchor: apache-hudi
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-hudi.png
  logosmall: /assets/images/logos/apache-hudi-small.png
  description: |
    Apache Hudi is a transactional data lake platform that brings database and
    data warehouse capabilities to the data lake. Hudi reimagines slow
    old-school batch data processing with a powerful new incremental processing
    framework for low latency minute-level analytics.

    Use an Apache Hudi data lake as a data source in Trino by configuring a
    catalog with the Hudi connector.
  links:
    - urltext: Apache Hudi
      url: https://hudi.apache.org/
    - urltext: Hudi connector documentation
      url: /docs/current/connector/hudi.html
    - urltext: Interview with Hudi contributors from Trino Community Broadcast
        41
      url: /episodes/41.html
- name: Apache Iceberg
  anchor: apache-iceberg
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-iceberg.png
  logosmall: /assets/images/logos/apache-iceberg-small.png
  description: |
    Apache Iceberg is a high-performance format for huge analytic tables.
    Iceberg brings the reliability and simplicity of SQL tables to big data,
    while making it possible for engines like Spark, Trino, Flink, Presto, Hive
    and Impala to safely work with the same tables, at the same time.

    Use an Apache Iceberg data lakehouse as a data source in Trino by
    configuring a catalog with the Iceberg connector.
  links:
    - urltext: Apache Iceberg
      url: https://iceberg.apache.org/
    - urltext: Iceberg connector documentation
      url: /docs/current/connector/iceberg.html
    - urltext: Interview with Iceberg creator from Trino Community Broadcast 40
      url: /episodes/40.html
# there are lots more from Trino Fest, Trino Summot .. need to figure out how many we are happy to have..
- name: Apache Ignite
  anchor: apache-ignite
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-ignite.png
  logosmall: /assets/images/logos/apache-ignite-small.png
  description: |
    Apache Ignite is a distributed in‑memory database for high‑performance
    applications. It scales across memory, disk, and multiple machines without
    compromise.

    Use an Apache Ignite database as a data source in Trino by configuring a
    catalog with the Apache Ignite connector.
  links:
    - urltext: Apache Ignite
      url: https://ignite.apache.org/
    - urltext: Ignite connector documentation
      url: /docs/current/connector/ignite.html
    - urltext: Interview about the Ignite connector from Trino Community
        Broadcast 46
      url: /episodes/46.html
- name: Apache Kafka
  anchor: apache-kafka
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-kafka.png
  logosmall: /assets/images/logos/apache-kafka-small.png
  description: |
    Apache Kafka is an open source distributed event streaming platform used by
    thousands of companies for high-performance data pipelines, streaming
    analytics, data integration, and mission-critical applications.

    Use an Apache Kafka event stream as a data source in Trino by configuring a
    catalog with the Kafka connector.
  links:
    - urltext: Apache Kafka
      url: https://kafka.apache.org/
    - urltext: Kafka connector documentation
      url: /docs/current/connector/kafka.html
- name: Apache Kudu
  anchor: apache-kudu
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-kudu.png
  logosmall: /assets/images/logos/apache-kudu-small.png
  description: |
    Apache Kudu is an open source distributed data storage engine that makes
    fast analytics on fast and changing data easy.

    Use an Apache Kudu data storage as a data source in Trino by configuring a
    catalog with the Kudu connector.
  links:
    - urltext: Apache Kudu
      url: https://kudu.apache.org/
    - urltext: Kudu connector documentation
      url: /docs/current/connector/kudu.html
- name: Apache ORC
  anchor: apache-orc
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-orc.png
  logosmall: /assets/images/logos/apache-orc-small.png
  description: |
    Apache ORC is a self-describing type-aware columnar file format designed
    for Hadoop workloads. It is optimized for large streaming reads, but with
    integrated support for finding required rows quickly. Storing data in a
    columnar format lets the reader read, decompress, and process only the
    values that are required for the current query.

    Access ORC files from Trino with the built-in readers and writers used by
    the Hive or Iceberg connector.
  links:
    - urltext: Apache ORC
      url: https://orc.apache.org/
    - urltext: Trino ORC configuration properties
      url: /docs/current/object-storage/file-formats.html#orc-format-configuration-properties
- name: Apache Parquet
  anchor: apache-parquet
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-parquet.png
  logosmall: /assets/images/logos/apache-parquet-small.png
  description: |
    Apache Parquet Apache Parquet is an open source, column-oriented data file
    format designed for efficient data storage and retrieval. It provides high
    performance compression and encoding schemes to handle complex data in bulk
    and is supported in many programming language and analytics tools...

    Access ORC files from Trino with the built-in readers and writers used by
    the Delta Lake, Hive, Hudi or Iceberg connectors.
  links:
    - urltext: Apache Parquet
      url: https://parquet.apache.org/
    - urltext: Trino Parquet configuration properties
      url: /docs/current/object-storage/file-formats.html#parquet-format-configuration-properties
- name: Apache Phoenix
  anchor: apache-phoenix
  category: data-source
  owner: other
  logo: /assets/images/logos/apache-phoenix.png
  logosmall: /assets/images/logos/apache-phoenix-small.png
  description: |
    Note that the Phoenix connector is removed from Trino 473 and later, and no
    longer maintained. Users must retrieve and update the code from the source
    code repository, or use an old Trino version.

    Apache Phoenix enables OLTP and operational analytics in Hadoop for low
    latency applications by combining the best of both worlds:

    * The power of standard SQL and JDBC APIs with full ACID transaction
      capabilities and
    * The flexibility of late-bound, schema-on-read
      capabilities from the NoSQL world by leveraging HBase as its backing store

    Use a Apache Phoenix key value store as a data source in Trino by
    configuring a catalog with the Phoenix connector.
  links:
    - urltext: Apache Phoenix
      url: https://phoenix.apache.org/
    - urltext: Phoenix connector documentation
      url: /docs/472/connector/phoenix.html
- name: Apache Pinot
  anchor: apache-pinot
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/apache-pinot.png
  logosmall: /assets/images/logos/apache-pinot-small.png
  description: |
    Apache Pinot is a real-time distributed OLAP datastore, designed to answer
    OLAP queries with low latency

    Use an Apache Pinot datastore as a data source in Trino by configuring a
    catalog with the Pinot connector.
  links:
    - urltext: Apache Pinot
      url: https://pinot.apache.org/
    - urltext: Pinot connector documentation
      url: /docs/current/connector/pinot.html
    - urltext: Trino takes a sip of Pinot! from Trino Community Broadcast 13
      url: /episodes/13.html
- name: Apache Polaris
  anchor: apache-polaris
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/apache-polaris.png
  logosmall: /assets/images/logos/apache-polaris-small.png
  description: |
    Apache Polaris is an open-source, fully-featured catalog for Apache
    Iceberg™. It implements Iceberg's REST API, enabling seamless multi-engine
    interoperability across a wide range of platforms,

    Use Lakekeeper with the Trino Iceberg connector and the configuration for a
    Iceberg REST catalog.
  links:
    - urltext: Apache Polaris
      url: https://polaris.apache.org/
    - urltext: Iceberg connector documentation
      url: /docs/current/connector/iceberg.html
    - urltext: Iceberg REST catalog configuration
      url: /docs/current/connector/iceberg.html#rest-catalog
- name: Apache Ranger
  anchor: apache-ranger
  category: add-on
  logo: /assets/images/logos/apache-ranger.png
  logosmall: /assets/images/logos/apache-ranger-small.png
  description: |
    Apache Ranger is a framework to enable, monitor, and manage comprehensive
    data security across the Hadoop platform.

    The Trino plugin enables the use of Apache Ranger as authorization
    engine for access control to catalogs, schemas, tables, and other objects in
    Trino. Policies are defined in Apache Ranger, and Trino checks access control
    privileges in Apache Ranger.
  links:
    - urltext: Apache Ranger
      url: https://ranger.apache.org/
    - urltext: Apache Ranger access control documentation
      url: /docs/current/security/apache-ranger-access-control.html
    - urltext: Announcement blog post
      url: /blog/2024/12/02/ranger.html
- name: Apache Superset
  anchor: apache-superset
  category: client-application
  logo: /assets/images/logos/superset.png
  logosmall: /assets/images/logos/superset-small.png
  description: |
    Apache Superset enables users to consume data in many different ways:
    writing SQL queries, creating new tables, creating a visualization
    (slice), adding that visualization to one or many dashboards and
    downloading a CSV. SQL Lab is a a part of Superset and provides a rich
    SQL editor that enables users to both query and visualize data. You
    can explore and preview tables in Trino, effortlessly compose SQL
    queries to access data. From there, you can either export a CSV file
    or immediately visualize your data in the Superset "Explore" view.
  links:
    - urltext: Apache Superset
      url: https://superset.apache.org/
    - urltext: Apache Superset - Trino configuration
      url: https://superset.apache.org/docs/databases/trino
    - urltext: Tutorial
      url: https://docs.starburst.io/data-consumer/clients/superset.html
    - urltext: Visualizing Trino with Apache Superset at Trino Summit 2023
      url: https://www.youtube.com/watch?v=idk0GMxs8vE
    - urltext: Trino gets super visual with Apache Superset! from Trino
        Community Broadcast 12
      url: /episodes/12.html
- name: Azure Storage
  anchor: azure-storage
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/microsoft-azure.png
  logosmall: /assets/images/logos/microsoft-azure-small.png
  description: |
    Azure Storage is a scalable, durable, and secure cloud storage solution from
    Microsoft. It offers a variety of storage options, including Blob Storage,
    which is ideal for data lakes and lakehouses. Azure Storage provides high
    availability, strong consistency, and disaster recovery capabilities, making
    it suitable for storing and managing large volumes of unstructured data.
    With Azure Storage, you can easily integrate with other Azure services and
    third-party tools to build comprehensive data solutions.

    Use Azure Storage with the Delta Lake, Hive, Hudi, or Iceberg connectors to
    access data in Azure Storage.
  links:
    - urltext: Azure Storage
      url: https://learn.microsoft.com/en-us/azure/storage/
    - urltext: Azure Storage file system support documentation
      url: /docs/current/object-storage/file-system-azure.html
- name: Backblaze
  anchor: backblaze
  category: data-lake
  owner: other
  logo: /assets/images/logos/backblaze.png
  logosmall: /assets/images/logos/backblaze-small.png
  description: |
    Backblaze B2 Cloud Storage is a scalable and cost-effective cloud storage
    solution designed for storing and managing large amounts of data. It offers
    high durability, availability, and performance, making it suitable for a
    wide range of use cases, including backups, data archiving, and serving
    media files. Backblaze B2 provides easy integration with various tools and
    services, allowing seamless data access and management.

    Use the Trino S3 file system support with the Delta Lake, Hive, Hudi, or
    Iceberg connectors to access data in Backblaze B2.
  links:
    - urltext: Backblaze
      url: https://www.backblaze.com/
    - urltext: Storing and Querying Analytical Data in Backblaze B2 and Trino
      url: https://www.backblaze.com/blog/storing-and-querying-analytical-data-in-backblaze-b2/
    - urltext: S3 file system support documentation
      url: /docs/current/object-storage/file-system-s3.html
- name: C# and ADO.NET
  anchor: c-sharp
  category: client-driver
  owner: trinodb
  logo: /assets/images/logos/dotnet.png
  logosmall: /assets/images/logos/dotnet-small.png
  description: |
    The Trino C# client project provides a streaming client library with ADO.NET
    interfaces for usage on the .NET platform. It enables applications using the
    .NET platform and running on Windows and other supported operating systems
    to connect and query Trino catalogs and process the results.
  links:
    - urltext: Trino C# client project
      url: https://github.com/trinodb/trino-csharp-client
    - urltext: Project introduction at Trino Summit 2024
      url: https://youtu.be/x2rF6IEjFK0
- name: CLI
  anchor: cli
  category: client-application
  owner: trinodb
  logo: /assets/images/logos/cli.png
  logosmall: /assets/images/logos/cli-small.png
  description: |
    The Trino CLI is a feature-rich command line interface tool for interactive
    query processing with Trino. The batch mode allows you to integrate the CLI
    with any other processing and automation that supports command line
    interactions.
  links:
    - urltext: Trino CLI documentation and download
      url: /docs/current/client/cli.html
    - urltext: User guide
      url: https://docs.starburst.io/data-consumer/clients/cli.html
- name: Clickhouse
  anchor: clickhouse
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/clickhouse.png
  logosmall: /assets/images/logos/clickhouse-small.png
  description: |
    ClickHouse is the fastest and most resource efficient open source real-time
    database for applications and analytics.

    Use a Clickhouse database as a data source in Trino by configuring a catalog
    with the Clickhouse connector.
  links:
    - urltext: Clickhouse
      url: https://clickhouse.com/
    - urltext: Clickhouse connector documentation
      url: /docs/current/connector/clickhouse.html
- name: Coginiti
  anchor: coginiti
  category: client-application
  owner: other  
  logo: /assets/images/logos/coginiti.png
  logosmall: /assets/images/logos/coginiti-small.png
  description: |
    Coginiti offers a comprehensive solution for data professionals, integrating
    essential functionalities such as modular development, version control,
    feedback mechanisms, testing capabilities, and documentation tools. By
    leveraging these features, analysts and data engineers can improve analytic
    consistency, increase productivity, and expedite the delivery of valuable
    insights.

    Unlock a new data analytics paradigm with Coginiti’s full support for Trino,
    a game-changer in large-scale data querying.
  links:
    - urltext: Coginiti
      url: https://www.coginiti.co
    - urltext: Coginiti as enterprise SQL workspace for Trino
      url: https://www.coginiti.co/databases/trino/
    - urltext: Interview and demo with Coginiti from Trino Community Broadcast 53
      url: /episodes/53.html
- name: Cube
  anchor: cube
  category: client-application
  owner: other
  logo: /assets/images/logos/cube.png
  logosmall: /assets/images/logos/cube-small.png
  description: |
    Cube is headless BI for building data apps. You can use Cube to create an
    additional semantic layer or a last-mile caching layer on top of Trino. More
    importantly, you can use the set of APIs that Cube provides, including REST
    API, GraphQL API, and SQL API, to deliver the data directly to custom-built
    front-end applications as well as BI tools and notebooks, retaining low
    latency and high concurrency.
  links:
    - urltext: Cube
      url: https://cube.dev/
    - urltext: Trino as data source with Cube
      url: https://cube.dev/integrations/Trino-Data-API
    - urltext: Announcement blog post
      url: https://cube.dev/blog/cube-integration-with-trino-sql-query-engine-for-big-data
- name: Datadog
  anchor: datadog
  category: add-on
  owner: other
  logo: /assets/images/logos/datadog.png
  logosmall: /assets/images/logos/datadog-small.png
  description: |
    The Datadog integration allows the observability service for cloud-scale
    applications to monitor your Trino cluster. It accesses the [JMX metrics
    provided by Trino](/docs/current/admin/jmx.html), and exposes them in
    Datadog for monitoring, inspection, and troubleshooting purposes.
  links:
    - urltext: Datadog
      url: https://www.datadoghq.com/
    - urltext: Documentation for Trino integration
      url: https://docs.datadoghq.com/integrations/trino/
- name: Datafaker
  anchor: datafaker
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/datafaker.png
  logosmall: /assets/images/logos/datafaker-small.png
  description: |
    Datafaker is a library to generate fake data. This can be very helpful
    when generating test data to fill a database, to generate data for a
    stress test, or anonymize data from production services.

    Use Datafaker as a data source in Trino by configuring a catalog with
    the Faker connector.
  links:
    - urltext: Datafaker
      url: https://www.datafaker.net/
    - urltext: Faker connector documentation
      url: /docs/current/connector/faker.html
    - urltext: Interview and demo with the Faker connector author Jan Waś in 
        Trino Community Broadcast 71
      url: /episodes/71.html
- name: DBeaver
  anchor: DBeaver
  category: client-application
  owner: other
  logo: /assets/images/logos/dbeaver.png
  logosmall: /assets/images/logos/dbeaver-small.png
  description: |
      DBeaver is a cross-platform database tool for developers, database
      administrators, analysts, and everyone working with data. With DBeaver you
      are able to manipulate with your data like in a regular spreadsheet,
      create analytical reports based on records from different data storages,
      export information in an appropriate format. For advanced database users
      DBeaver suggests a powerful SQL-editor, plenty of administration features,
      abilities of data and schema migration, monitoring database connection
      sessions, and a lot more.

      It is avaiable as free open source DBeaver Community and as various
      commercially supported DBeaver PRO editions. A web application version
      called CloudBeaver is also available. All editions support many databases,
      including Trino.
  links:
    - urltext: DBeaver Community
      url: https://dbeaver.io/
    - urltext: DBeaver PRO
      url: https://dbeaver.com/
    - urltext: CloudBeaver
      url: https://dbeaver.com/docs/cloudbeaver/
    - urltext: DBeaver and Trino guide
      url: https://docs.starburst.io/data-consumer/clients/dbeaver.html
- name: dbt
  anchor: dbt
  category: client-application
  owner: other
  logo: /assets/images/logos/dbt.png
  logosmall: /assets/images/logos/dbt-small.png
  description: |
    dbt is a transformation workflow that helps you get more work done while
    producing higher quality results. You can use dbt to modularize and
    centralize your analytics code, while also providing your data team with
    guardrails typically found in software engineering workflows. Collaborate on
    data models, version them, and test and document your queries before safely
    deploying them to production, with monitoring and visibility.
  links:
    - urltext: dbt
      url: https://www.getdbt.com/
    - urltext: dbt documentation
      url: https://docs.getdbt.com/
    - urltext: dbt configuration for Trino
      url: https://docs.getdbt.com/reference/resource-configs/trino-configs
    - urltext: dbt-trino plugin
      url: https://github.com/starburstdata/dbt-trino
    - urltext: Interview with dbt developers from Trino Community Broadcast 30
      url: /episodes/30.html
    - urltext: Introduction to dbt and Trino from Trino Community Broadcast 21
      url: /episodes/21.html
- name: DbVisualizer
  anchor: dbvisualizer
  category: client-application
  owner: other
  logo: /assets/images/logos/dbvisualizer.png
  logosmall: /assets/images/logos/dbvisualizer-small.png
  description: |
    DbVisualizer is a universal database tool for querying, managing, and
    visualizing data, with a long history of being a top-performing Trino
    editor.

    Use DbVisualizer to easily connect to and query your Trino catalogs. With
    extended support for Trino-specific object types, you can enjoy the full
    suite of smart features that DbVisualizer has to offer.
  links:
    - urltext: DbVisualizer website
      url: https://www.dbvis.com/
    - urltext: DbVisualizer - Trino overview
      url: https://www.dbvis.com/database/trino/
    - urltext: Mastering the Trino Connection with DbVisualizer
      url: https://www.dbvis.com/thetable/mastering-the-trino-connection-unleash-the-power-of-dbvisualizer/
    - urltext: DbVisualizer Docs
      url: https://www.dbvis.com/docs/ug/
- name: Delta Lake
  anchor: delta-lake
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/delta-lake.png
  logosmall: /assets/images/logos/delta-lake-small.png
  description: |
    Delta Lake is an open source storage framework that enables building a
    Lakehouse architecture with compute engines including Spark, PrestoDB,
    Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.

    Use a Delta Lake data lakehouse as a data source in Trino by configuring a
    catalog with the Delta Lake connector.
  links:
    - urltext: Delta Lake
      url: https://delta.io/
    - urltext: Delta Lake connector documentation
      url: /docs/current/connector/delta-lake.html
    - urltext: Interview about new Delta Lake connector from Trino Community
        Broadcast 34
      url: /episodes/34.html
- name: Elasticsearch
  anchor: elasticsearch
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/elasticsearch.png
  logosmall: /assets/images/logos/elasticsearch-small.png
  description: |
    Elasticsearch is a distributed, RESTful search and analytics engine capable
    of addressing a growing number of use cases. As the heart of the Elastic
    Stack, it centrally stores your data for lightning fast search, fine‑tuned
    relevancy, and powerful analytics that scale with ease.

    Use an Elasticsearch index as a data source in Trino by configuring a
    catalog with the Elasticsearch connector.
  links:
    - urltext: Elasticsearch
      url: https://www.elastic.co/elasticsearch/
    - urltext: Elasticsearch connector documentation
      url: /docs/current/connector/elasticsearch.html
- name: Elixir
  anchor: elixir
  category: client-driver
  owner: other
  logo: /assets/images/logos/elixir.png
  logosmall: /assets/images/logos/elixir-small.png
  description: |
    Elixir is a dynamic, functional language for building scalable and maintainable
    applications.

    Elixir runs on the Erlang VM, known for creating low-latency, distributed, and
    fault-tolerant systems. These capabilities and Elixir tooling allow developers
    to be productive in several domains, such as web development, embedded software,
    machine learning, data pipelines, and multimedia processing, across a wide range
    of industries.

    Use the req_trino to connect an Elixir script or application to a Trino cluster
    and receive the results of the submitted queries.
  links:
    - urltext: Elixir
      url: https://elixir-lang.org/
    - urltext: req_trino
      url: https://github.com/ndrluis/req_trino
- name: Emacs
  anchor: emacs
  category: client-application
  owner: other
  logo: /assets/images/logos/emacs.png
  logosmall: /assets/images/logos/emacs-small.png
  description: |
    GNU Emacs, a versatile and extensible text editor, offers support for
    numerous programming languages and tools, including SQL. If you're
    interested in using Emacs to work with SQL databases, the built-in sql-mode
    and sql-interactive-mode are your friends. To use it with Trino include the
    sql-trino.el mode.
  links:
    - urltext: GNU Emacs
      url: https://www.gnu.org/software/emacs/
    - urltext: sql-trino.el
      url: https://github.com/regadas/sql-trino
- name: Exasol
  anchor: exasol
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/exasol.png
  logosmall: /assets/images/logos/exasol-small.png
  description: |
    Exasol is an in-memory, column-oriented, relational database management
    system known for its high performance and its usage of a massively parallel
    processing architecture.

    Use an Exasol database as a data source in Trino by configuring a catalog
    with the Exasol connector.
  links:
    - urltext: Exasol
      url: https://www.exasol.com/
    - urltext: Exasol connector documentation
      url: /docs/current/connector/exasol.html
- name: FugueSQL
  anchor: fugue-sql
  category: client-application
  owner: other
  logo: /assets/images/logos/fuguesql.png
  logosmall: /assets/images/logos/fuguesql-small.png
  description: |
    Fugue provides an easier interface to using distributed compute effectively
    and accelerates big data projects. It does this by minimizing the amount of
    code you need to write, in addition to taking care of tricks and
    optimizations that lead to more efficient execution on distrubted compute.
    Fugue ports Python, Pandas, and SQL code to Spark, Dask, and Ray, and
    supports Trino.
  links:
    - urltext: FugueSQL
      url: https://fugue-tutorials.readthedocs.io/index.html
    - urltext: Fugue with Trino documentation
      url: https://fugue-tutorials.readthedocs.io/tutorials/integrations/warehouses/trino.html
    - urltext: Interoperable Python and Trino for interactive workloads
        from TrinoFest 2023
      url: /blog/2023/07/27/trino-fest-2023-fugue-recap
- name:  Git
  anchor: git
  category: data-source
  owner: other
  logo: /assets/images/logos/git.png
  logosmall: /assets/images/logos/git-small.png
  description: |
    Git is a free and open source distributed version control system designed to
    handle everything from small to very large projects with speed and
    efficiency.

    Use a git repository as a data source in Trino by configuring a catalog with
    the git connector.
  links:
    - urltext: Git
      url: https://git-scm.com/
    - urltext: Trino git connector
      url: https://github.com/nineinchnick/trino-git
- name: Go
  anchor: go
  category: client-driver
  owner: trinodb
  logo: /assets/images/logos/go.png
  logosmall: /assets/images/logos/go-small.png
  description: |
    Go is a statically typed, compiled high-level programming language. Use the
    Trino Go client to connect a Go applications to a Trino cluster and receive
    the results of the submitted SQL queries.
  links:
    - urltext: Go
      url: https://go.dev/
    - urltext: Trino Go client source code and documentation
      url: https://github.com/trinodb/trino-go-client
- name: Google Cloud Storage
  anchor: google-cloud-storage
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/google-cloud-storage.png
  logosmall: /assets/images/logos/google-cloud-storage-small.png
  description: |
    Google Cloud Storage is a scalable, secure, and durable object storage
    service provided by Google Cloud. It offers high availability and
    performance, making it suitable for a wide range of use cases, including
    data lakes and lakehouses. Google Cloud Storage integrates seamlessly with
    other Google Cloud services and third-party tools, providing a comprehensive
    solution for storing, managing, and analyzing large volumes of unstructured
    data.

    Use the Trino Google Cloud Storage file system support with the Delta Lake,
    Hive, Hudi, or Iceberg connectors to access data in Google Cloud Storage.
  links:
    - urltext: Google Cloud Storage
      url: https://cloud.google.com/storage
    - urltext: Google Cloud Storage file system support documentation
      url: /docs/current/object-storage/file-system-gcs.html
- name: Google BigQuery
  anchor: google-bigquery
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/google-bigquery.png
  logosmall: /assets/images/logos/google-bigquerye-small.png
  description: |
    BigQuery is a serverless and cost-effective enterprise data warehouse that
    works across clouds and scales with your data. Use built-in ML/AI and BI for
    insights at scale.

    Use a Google BigQuery data warehouse as a data source in Trino by
    configuring a catalog with the BigQuery connector.
  links:
    - urltext: Google BigQuery
      url: https://cloud.google.com/bigquery/
    - urltext: BigQuery connector documentation
      url: /docs/current/connector/bigquery.html
- name: Google Sheets
  anchor: google-sheets
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/google-sheets.png
  logosmall: /assets/images/logos/google-sheets-small.png
  description: |
    Google Sheets enables you to ceate and collaborate on online spreadsheets
    in real-time and from any device.

    Use a Google Sheets spreadsheet as a data source in Trino by configuring a
    catalog with the Google Sheets connector.
  links:
    - urltext: Google Sheets
      url: https://www.google.com/sheets/about/
    - urltext: Google Sheets connector documentation
      url: /docs/current/connector/googlesheets.html
- name: Grafana
  anchor: grafana
  category: client-application
  owner: trinodb
  logo: /assets/images/logos/grafana.png
  logosmall: /assets/images/logos/grafana-small.png
  description: |
    Grafana is a multi-platform open source analytics and interactive
    visualization web application. It provides charts, graphs, and alerts for
    the web when connected to supported data sources.

    The Trino Grafana Data Source Plugin allows you to connect your Grafana
    dashboards to Trino and use the configured catalogs as data source.
  links:
    - urltext: Grafana
      url: https://grafana.com/
    - urltext: Trino Grafana Data Source Plugin
      url: https://github.com/trinodb/grafana-trino
- name: Gravitino
  anchor: gravitino
  category: data-lake
  owner: other
  logo: /assets/images/logos/gravitino.png
  logosmall: /assets/images/logos/gravitino-small.png
  description: |
    Gravitino is a high-performance, geo-distributed, and federated metadata
    lake. It manages the metadata directly in different sources, types, and
    regions. It also provides users with unified metadata access for data and AI
    assets, and is available as an open source project.

    Use Gravitino as a data source in Trino by configuring a catalog with the
    Gravitino connector.
  links:
    - urltext: Gravitino
      url: https://datastrato.ai/gravitino/
    - urltext: Gravitino Trino connector documentation
      url: https://datastrato.ai/docs/0.4.0/trino-connector/index
- name: Great Expectations
  anchor: great-expectations
  category: client-application
  owner: other
  logo: /assets/images/logos/great-expectations.png
  logosmall: /assets/images/logos/great-expectations-small.png
  description: |
    Great Expectations is the leading tool for validating, documenting, and
    profiling your data to maintain quality and improve communication between
    teams.
  links:
    - urltext: Great Expectations
      url: https://greatexpectations.io
    - urltext: Great Expectations documentation
      url: https://docs.greatexpectations.io/
    - urltext: Trino guide
      url: https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/database/trino/
    - urltext: Make your Trino data pipelines production ready with Great
        Expectations
      url: /blog/2022/08/24/data-pipelines-production-ready-great-expectations.html
- name: Gurubase
  anchor: gurubase
  category: add-on
  owner: other
  logo: /assets/images/logos/gurubase.png
  logosmall: /assets/images/logos/gurubase-small.png
  description: |
    Gurubase is an AI-based learning assistant designed to answer your questions.
    It includes Trino Guru, which generates answers using data from the official 
    Trino documentation.
  links:
    - urltext: Ask Trino Guru
      url: https://gurubase.io/g/trino
- name: Harlequin
  anchor: Harlequin
  category: client-application
  owner: other
  logo: /assets/images/logos/harlequin.png
  logosmall: /assets/images/logos/harlequin-small.png
  description: |
      Harlequin is a portable, powerful, colorful, easy, fast, and beautiful
      database client for the terminal. It runs on any shell, any terminal, and
      any machine.

      Harlequin is free to download and you install it with `pipx` or `pip` and
      the command `install harlequin_trino`.
  links:
    - urltext: Harlequin
      url: https://harlequin.sh/
    - urltext: Harlequin Trino adapter
      url: https://harlequin.sh/docs/trino/index
- name: Hue
  anchor: hue
  category: client-application
  owner: other
  logo: /assets/images/logos/hue.png
  logosmall: /assets/images/logos/hue-small.png
  description: |
    Hue is a mature open source SQL assistant for querying databases and data
    warehouses. It is used by Fortune 500 companies, and focused on smart query
    typing.
  links:
    - urltext: Hue
      url: http://gethue.com/
    - urltext: Instructions to use the Trino connector
      url: https://docs.gethue.com/administrator/configuration/connectors/#trino
- name: Ibis
  anchor: ibis
  category: client-application
  owner: other
  logo: /assets/images/logos/ibis.png
  logosmall: /assets/images/logos/ibis-small.png
  description: |
    Ibis is a dataframe interface to execution engines with support for 15+
    backends, including Trino. Ibis doesn’t replace your existing execution
    engine, it extends it with powerful abstractions and intuitive syntax. For
    those who love doing all their data-related work in Python, this allows you
    to write Python code that leverages the speed and power of Trino without
    needing to become a SQL master.
  links:
    - urltext: Ibis Project
      url: https://ibis-project.org/
    - urltext: Trino as Ibis backend
      url: https://ibis-project.org/backends/trino/
    - urltext: Because SQL is everywhere and so is Python from TrinoFest 2023
      url: /blog/2023/07/03/trino-fest-2023-ibis.html
    - urltext: Trino, Ibis, and wrangling Python in the SQL ecosystem from Trino
        Community Broadcast 49
      url: /episodes/49.html
- name: IBM Cognos Analytics
  anchor: ibm-cognos-analytics
  category: client-application
  owner: other
  logo: /assets/images/logos/ibm-cognos-analytics.png
  logosmall: /assets/images/logos/ibm-cognos-analytics-small.png
  description: |
    Cognos Analytics is a comprehensive business intelligence and performance
    management suite providing robust reporting, dashboards, data modeling and
    real-time monitoring, score carding, and predictive analytics. Cognos
    Analytics aims to empower users to collaborate, plan, and make smart
    decisions for better business results.
  links:
    - urltext: IBM Cognos Analytics
      url: https://www.ibm.com/products/cognos-analytics
    - urltext: List of supported software, including Trino versions
      url: https://www.ibm.com/support/pages/node/6966712
- name: JavaScript
  anchor: javascript
  category: client-driver
  owner: trinodb
  logo: /assets/images/logos/javascript.png
  logosmall: /assets/images/logos/javascript-small.png
  description: |
    Applications using JavaScript, TypeScript, Node.js, and related frameworks
    can use the trino-js-client to connect to a Trino cluster and receive the
    results of the submitted queries.
  links:
    - urltext: trino-js-client
      url: https://github.com/trinodb/trino-js-client
- name: JDBC
  anchor: jdbc
  category: client-driver
  owner: trinodb
  logo: /assets/images/logos/jdbc.png
  logosmall: /assets/images/logos/jdbc-small.png
  description: |
    Java Database Connectivity (JDBC) enables applications running on the JVM to
    connect and query databases. Use the Trino JDBC driver with your application
    for the JVM, written in Java, Kotlin, or any other JVM language, or provided
    by your tool vendor.
  links:
    - urltext: Trino JDBC Driver documentation
      url: /docs/current/client/jdbc.html
- name: JetBrains Datagrip
  anchor: jetbrains-datagriop
  category: client-application
  owner: other
  logo: /assets/images/logos/datagrip.png
  logosmall: /assets/images/logos/datagrip-small.png
  description: |
    DataGrip by JetBrains is an IDE for databases that is tailored to suit the
    specific needs of professional SQL developers. It is designed to work with
    databases installed locally, on a server, or in the cloud. It is installed
    as a local application on your workstation.
  links:
    - urltext: JetBrains Datagrip
      url: https://www.jetbrains.com/datagrip/
    - urltext: Datagrip with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/datagrip.html
- name: JMX
  anchor: jmx
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/jmx.png
  logosmall: /assets/images/logos/jmx-small.png
  description: |
    Java Management Extensions (JMX) is a Java technology that supplies tools
    for managing and monitoring applications, system objects, devices (such as
    printers) and service-oriented networks. It defines a management
    architecture, design patterns, APIs, and services for building web-based,
    distributed, dynamic, and modular solutions to manage Java-enabled
    resources.

    Trino exposes numerous metrics for JMX. The metrics can be
    inspected and monitored with external JMX application, and in Trino itself
    with SQL statements and the included JMX connector.
  links:
    - urltext: JMX
      url: https://www.oracle.com/technical-resources/articles/javase/jmx.html
    - urltext: Monitoring with JMX
      url: /docs/current/admin/jmx.html
    - urltext: JMX connector
      url: /docs/current/connector/jmx.html
- name: jOOQ
  anchor: jooq
  category: add-on
  owner: other
  logo: /assets/images/logos/jooq.png
  logosmall: /assets/images/logos/jooq-small.png
  description: |
    jOOQ stands for jOOQ Object Oriented Querying (jOOQ). It generates Java code
    from your database, and lets you build type safe SQL queries through its
    fluent API.

    All editions of jOOQ since the 3.19 release include support for Trino. The
    level of support depends on the used catalog and connector, and further
    Trino-specific enhancements are in progress.
  links:
    - urltext: Java Object Oriented Querying (JOOQ)
      url: https://www.jooq.org/
    - urltext: jOOQ 3.19 release notes
      url: https://www.jooq.org/notes
    - urltext: Trino Community Broadcast 59 - Querying Trino with Java and jOOQ
      url: /episodes/59.html
- name: Jupy SQL
  anchor: jupy-sql
  category: client-application
  owner: other
  logo: /assets/images/logos/jupy-sql.png
  logosmall: /assets/images/logos/jupy-sql-small.png
  description: |
    JupySQL allows you to run SQL and plot large datasets in Jupyter a `%sql`,
    %%sql, and %sqlplot magics. JupySQL is compatible with all major databases,
    data warehouses, embedded engines, and of course also Trino.
  links:
    - urltext: Jupy SQL
      url: https://jupysql.ploomber.io/
    - urltext: Trino tutorial
      url: https://jupysql.ploomber.io/en/latest/integrations/trinodb.html
- name: Kubernetes
  anchor: kubernetes
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/kubernetes.png
  logosmall: /assets/images/logos/kubernetes-small.png
  description: |
    Trino is commonly deployed on the Kubernetes platform. Use the Docker
    container directly or with the Helm chart for your deployment. In addition,
    numerous vendors provide custom tooling to manage Trino with their specific
    products and integrations using Kubernetes.
  links:
    - urltext: Kubernetes
      url: https://kubernetes.io/
    - urltext: Trino Docker container documentation
      url: /docs/current/installation/containers.html
    - urltext: Trino Helm chart documentation
      url: /docs/current/installation/kubernetes.html
    - urltext: Trino Helm chart source with more details
      url:  https://github.com/trinodb/charts
- name: Lakekeeper
  anchor: lakekeeper
  category: data-lake
  owner: other
  logo: /assets/images/logos/Lakekeeper.png
  logosmall: /assets/images/logos/lakekeeper-small.png
  description: |
    Lakekeeper is an Apache-Licensed, secure, fast, and easy-to-use Apache
    Iceberg REST Catalog written in Rust. It provides a scalable solution for
    managingLakehouses with enterprise-grade governance. Key features include
    Kubernetes and OpenID integration, fine-grained access control, and
    multi-tenancy. Designed for interoperability, it supports major cloud
    providers as well as on-premise deployments. Lakekeeper emits change events,
    ensures high availability, and offers a lightweight, easily deployable
    architecture. Prioritizing ecosystem-wide compatibility, it empowers
    organizations to manage their Lakehouse infrastructure without vendor
    lock-in.

    Use Lakekeeper with the Trino Iceberg connector and the configuration for a
    Iceberg REST catalog.
  links:
    - urltext: Lakekeeper
      url: https://lakekeeper.io/
    - urltext: Iceberg connector documentation
      url: /docs/current/connector/iceberg.html
    - urltext: Iceberg REST catalog documentation
      url: /docs/current/object-storage/metastores.html#rest-catalog
- name: Looker
  anchor: looker
  category: client-application
  owner: other
  logo: /assets/images/logos/looker.png
  logosmall: /assets/images/logos/looker-small.png
  description: |
    Looker offers a unified business intelligence platform on Google Cloud. It
    is self-service and governance enabled, and can be embedded in your
    solution.
  links:
    - urltext: Looker
      url: https://cloud.google.com/looker
    - urltext: Looker and Trino user guide
      url: https://cloud.google.com/looker/docs/db-config-prestodb-and-trino
- name: MariaDB
  anchor: mariadb
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/mariadb.png
  logosmall: /assets/images/logos/mariadb-small.png
  description: |
    MariaDB Server is one of the most popular open source relational databases.
    It’s made by the original developers of MySQL and guaranteed to stay open
    source. It is part of most cloud offerings and the default in most Linux
    distributions.

    Use a MariaDB database as a data source in Trino by configuring a catalog
    with the MariaDB connector.
  links:
    - urltext: MariaDB
      url: https://mariadb.org/
    - urltext: MariaDB connector documentation
      url: /docs/current/connector/mariadb.html
- name: Metabase
  anchor: metabase
  category: client-application
  owner: other
  logo: /assets/images/logos/metabase.png
  logosmall: /assets/images/logos/metabase-small.png
  description: |
    Metabase is an open source web based business intelligence platform. You can
    use Metabase to ask questions about your data, or embed Metabase in your app
    to let your customers explore their data on their own. More information is
    available in the driver project repository and the user guide.
  links:
    - urltext: Metabase
      url: https://www.metabase.com/
    - urltext: Metabase driver user guide
      url: https://docs.starburst.io/data-consumer/clients/metabase.html
    - urltext: Metabase driver
      url: https://github.com/starburstdata/metabase-driver
    - urltext: Interview about Metabase from Trino Community Broadcast 44
      url: /episodes/44.html
- name: Microsoft SQL Server
  anchor: sql-server
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/microsoft-sql-server.png
  logosmall: /assets/images/logos/microsoft-sql-server-small.png
  description: |
    Microsoft SQL Server is a proprietary relational database management system
    developed by Microsoft. Microsoft provides different editions of Microsoft
    SQL Server, aimed at different audiences and for workloads ranging from
    small single-machine applications to large Internet-facing applications with
    many concurrent users.

    Use a Microsoft SQL Server database as a data source in Trino by configuring
    a catalog with the SQL Server connector.
  links:
    - urltext: Microsoft SQL Server
      url: https://www.microsoft.com/sql-server
    - urltext: SQL Server connector documentation
      url: /docs/current/connector/sqlserver.html
- name: Microstrategy
  anchor: microstrategy
  category: client-application
  owner: other
  logo: /assets/images/logos/microstrategy.png
  logosmall: /assets/images/logos/microstrategy-small.png
  description: |
    MicroStrategy is a business intelligence tool that enables you to build up
    platforms that provide real-time data monitoring and can be accessed and
    controlled over any mobile device upon creation. It provides modern
    analytics on an open, comprehensive enterprise platform, and allows users to
    overlay actionable enterprise data on popular business applications to help
    users make smarter, faster decisions.
  links:
    - urltext: Microstrategy
      url: https://www.microstrategy.com/en
    - urltext: Microstrategy with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/microstrategy.html
- name: MinIO
  anchor: minio
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/minio.png
  logosmall: /assets/images/logos/minio-small.png
  description: |
    MinIO is a high-performance, distributed object storage system designed for
    data lake and lakehouse use cases. It is compatible with the Amazon S3 API,
    making it easy to integrate with existing applications and tools that
    support S3. MinIO is optimized for large-scale data storage and retrieval,
    providing high availability, durability, and performance.

    Use the Trino S3 file system support with the Delta Lake, Hive, Hudi, or
    Iceberg connectors to access data in MinIO.
  links:
    - urltext: MinIO
      url: https://min.io/
    - urltext: MinIO for modern datalakes
      url: https://min.io/solutions/modern-data-lakes-lakehouses
    - urltext: S3 file system support documentation
      url: /docs/current/object-storage/file-system-s3.html      
- name: Minitrino
  anchor: minitrino
  category: add-on
  owner: other
  logo: /assets/images/logos/minitrino.png
  logosmall: /assets/images/logos/minitrino-small.png
  description: |
    Minitrino is a command line tool that makes it easy to run modular Trino
    environments locally. It uses a collection of Docker images to deploy
    various containers alongside Trino, including data sources, security
    integrations, and administration tools.
  links:
    - urltext: Minitrino
      url: https://github.com/jefflester/minitrino
- name: Mitzu
  anchor: mitzu
  category: client-application
  owner: other
  logo: /assets/images/logos/mitzu.png
  logosmall: /assets/images/logos/mitzu-small.png
  description: |
    Mitzu is a warehouse-native product analytics platform that revolutionizes
    how companies leverage their product usage data in the data lake.

    By directly connecting to Trino, Mitzu eliminates the need for traditional
    reverse ETL processes to 3rd party applications such as Amplitude or
    Mixpanel. Mitzu enables real-time self-served product analytics on top of
    the existing data infrastructure with generated SQL queries.
  links:
    - urltext: Mitzu
      url: https://www.mitzu.io/
    - urltext: Setup for Trino integration to Mitzu
      url: https://docs.mitzu.io/warehouse-integrations/trino-presto
    - urltext: Using Mitzu With Trino blog post
      url: https://www.mitzu.io/post/using-mitzu-with-trino-presto
    - urltext: Trino Community Broadcast 58, Understanding your users with Trino and Mitzu
      url: /episodes/58.html
- name: Mode
  anchor: mode
  category: client-application
  owner: other
  logo: /assets/images/logos/mode.png
  logosmall: /assets/images/logos/mode-small.png
  description: |
    Mode is the modern business intelligence platform that unites data teams
    with business teams to build analytics that drive business outcomes.
  links:
    - urltext: Mode
      url: https://www.mode.com/
    - urltext: Mode and Trino integration guide
      url: https://mode.com/integrations/trino/
- name: MongoDB
  anchor: mongodb
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/mongodb.png
  logosmall: /assets/images/logos/mongodb-small.png
  description: |
    MongoDB is a source-available cross-platform document-oriented database
    program. Classified as a NoSQL database program, MongoDB uses JSON-like
    documents with optional schemas.

    Use a MongoDB database as a data source in Trino by configuring a catalog
    with the MongoDB connector.
  links:
    - urltext: MongoDB
      url: https://www.mongodb.com/
    - urltext: MongoDB connector documentation
      url: /docs/current/connector/mongodb.html
- name: MySQL
  anchor: mysql
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/mysql.png
  logosmall: /assets/images/logos/mysql-small.png
  description: |
    MySQL is the world's most popular open source relational database management
    system (RDBMS).

    Use a MySQL database as a data source in Trino by configuring a catalog with
    the MySQL connector.
  links:
    - urltext: MySQL
      url: https://www.mysql.com/
    - urltext: MySQL connector documentation
      url: /docs/current/connector/mysql.html
- name: ODBC
  anchor: Odbc
  category: client-driver
  owner: other
  logo: /assets/images/logos/odbc.png
  logosmall: /assets/images/logos/odbc-small.png
  description: |
    Open Database Connectivity (ODBC) enables applications to connect and query
    databases. Use an ODBC driver with your own custom application, or with any
    other application that supports ODBC. ODBC drivers for Trino are available
    from Magnitude. Starburst customers receive an ODBC driver suitable for
    Starburst Enterprise and Starburst Galaxy.
  links:
    - urltext: Simba ODBC driver from insightsoftware
      url: https://insightsoftware.com/drivers/trino-odbc-jdbc/
    - urltext: Starburst ODBC driver
      url: https://docs.starburst.io/data-consumer/clients/odbc.html
- name: OpenAPI
  anchor: openapi
  category: data-source
  owner: other
  logo: /assets/images/logos/openapi.png
  logosmall: /assets/images/logos/openapi-small.png
  description: |
    OpenAPI is a specification language for REST APIs that provides a
    standardized means to define your API.

    Use any REST API that publishes an OpenAPI specification as a data source in
    Trino by configuring a catalog with the OpenAPI connector, and avoid having
    to generate a client.
  links:
    - urltext: OpenAPI
      url: https://www.openapis.org/
    - urltext: Trino OpenAPI connector
      url: https://github.com/nineinchnick/trino-openapi
- name: OpenLineage
  anchor: openlineage
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/openlineage.png
  logosmall: /assets/images/logos/openlineage-small.png
  description: |
    OpenLineage is an open source framework for data lineage collection and analysis.
    OpenLineage enables consistent collection of lineage metadata, creating a deeper
    understanding of how data is produced and used.

    Using the OpenLineage event listener, you can see the end to end lineage of all data
    that are modified by Trino queries.
  links:
    - urltext: OpenLineage
      url: https://openlineage.io/
    - urltext: OpenLineage event listener documentation
      url: /docs/current/admin/event-listeners-openlineage.html
    - urltext: Enhancing data governance at Apple with OpenLineage at Trino Fest 2024
      url: https://youtu.be/A7hj1M7IYj8
- name: Open Policy Agent
  anchor: opa
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/opa.png
  logosmall: /assets/images/logos/opa-small.png
  description: |
    Open Policy Agent (OPA) is a system for policy-based control for cloud
    native environments. It enables flexible, fine-grained control for
    administrators across many systems and applications.

    The Trino plugin enables the use of Open Policy Agent (OPA) as authorization
    engine for access control to catalogs, schemas, tables, and other objects in
    Trino. Policies are defined in OPA, and Trino checks access control
    privileges in OPA.
  links:
    - urltext: Open Policy Agent
      url: https://www.openpolicyagent.org/
    - urltext: Open Policy Agent access control documentation
      url: /docs/current/security/opa-access-control.html
    - urltext: Blog post about Open Policy Agent for Trino with videos from Trino Summit 2023
      url: http://trino.io/blog/2024/02/06/opa-arrived.html
- name: OpenSearch
  anchor: opensearch
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/opensearch.png
  logosmall: /assets/images/logos/opensearch-small.png
  description: |
    OpenSearch is a scalable, flexible, and extensible open-source software
    suite for search, analytics, and observability applications. OpenSearch
    offers a vendor-agnostic toolset you can use to build secure,
    high-performance, cost-efficient applications. OpenSearch includes a data
    store and search engine, a visualization and user interface, and a library
    of plugins you can use to tailor your tools to your requirements.

    Use an OpenSearch index as a data source in Trino by configuring a
    catalog with the Elasticsearch connector.
  links:
    - urltext: OpenSearch
      url: https://opensearch.org/
    - urltext: Elasticsearch connector documentation
      url: /docs/current/connector/elasticsearch.html
- name: OpenTelemetry
  anchor: opentelemetry
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/opentelemetry.png
  logosmall: /assets/images/logos/opentelemetry-small.png
  description: |
    OpenTelemetry is a widely-used collection of APIs, SDKs, and tools that
    instrument, generate, collect, and export telemetry data such as metrics,
    logs, and traces to help you analyze application performance and behavior.

    Trino exposes tracing information for observability of a running Trino
    deployment.
  links:
    - urltext: OpenTelemetry
      url: https://opentelemetry.io/
    - urltext: Trino observability with OpenTelemetry
      url: /docs/current/admin/opentelemetry.html
    - urltext: Trino Community Broadcast 57, Seeing clearly with OpenTelemetry
      url: /episodes/57.html
- name: Oracle
  anchor: oracle
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/oracle.png
  logosmall: /assets/images/logos/oracle-small.png
  description: |
    Oracle database services and products offer customers cost-optimized and
    high-performance versions of Oracle Database, the world's leading converged,
    multi-model database management system.

    Use an Oracle database as a data source in Trino by configuring a catalog
    with the Oracle connector.
  links:
    - urltext: Oracle
      url: https://www.oracle.com/database/
    - urltext: Oracle connector documentation
      url: /docs/current/connector/oracle.html
- name: PopSQL
  anchor: popsql
  category: client-application
  owner: other
  logo: /assets/images/logos/popsql.png
  logosmall: /assets/images/logos/popsql-small.png
  description: |
    PopSQL is a collaborative SQL editor for your team to write queries,
    visualize data, and share your results.
  links:
    - urltext: PopSQL
      url: https://popsql.com/
    - urltext: Connecting to Trino
      url: https://docs.popsql.com/docs/connecting-to-trino
    - urltext: Trino Community Broadcast 51 - Trino cools off with PopSQL
      url: /episodes/51.html
- name: PostgreSQL
  anchor: postgresql
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/postgresql.png
  logosmall: /assets/images/logos/postgresql-small.png
  description: |
    PostgreSQL is the world's most advanced open source relational database.
    PostgreSQL is a powerful system with over 35 years of active development
    that has earned it a strong reputation for reliability, feature robustness,
    and performance.

    Use a PostgreSQL database as a data source in Trino by configuring a catalog
    with the PostgreSQL connector.
  links:
    - urltext: PostgreSQL
      url: https://postgresql.org/
    - urltext: PostgreSQL connector documentation
      url: /docs/current/connector/postgresql.html
- name: Power BI
  anchor: power-bi
  category: client-application
  owner: other
  logo: /assets/images/logos/power-bi.png
  logosmall: /assets/images/logos/power-bi-small.png
  description: |
    Power BI is an interactive data visualization software product suite
    developed by Microsoft with a primary focus on business intelligence.

    Power BI users can query Trino clusters using a variety of available
    clients.
  links:
    - urltext: Power BI
      url: https://powerbi.microsoft.com/
    - urltext: Open source Power BI Trino connector
      url: https://github.com/CreativeDataEU/PowerBITrinoConnector
    - urltext: Commercial driver from Starburst
      url: https://docs.starburst.io/clients/powerbi.html
    - urltext: Azure HDInsight on AKS Trino including Power BI support
      url: https://learn.microsoft.com/power-query/connectors/azure-hdinsight-on-aks-trino
    - urltext: Trino Community Broadcast 61 about the open source connector project
      url: /episodes/61.html
- name: Prometheus
  anchor: prometheus
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/prometheus.png
  logosmall: /assets/images/logos/prometheus-small.png
  description: |
    Prometheus is an open source systems monitoring and alerting toolkit with a
    very active developer and user community. Prometheus collects and stores its
    metrics as time series data, i.e. metrics information is stored with the
    timestamp at which it was recorded, alongside optional key-value pairs
    called labels.

    Use a Prometheus database as a data source in Trino by configuring a catalog
    with the Prometheus connector.

    Trino also supports observability with OpenTelemetry, and therefore
    Prometheus.
  links:
    - urltext: Prometheus
      url: https://prometheus.io/docs/introduction/overview/
    - urltext: Prometheus connector documentation
      url: /docs/current/connector/prometheus.html
    - urltext: OpenTelemetry integration documentation
      url: /docs/current/admin/opentelemetry.html
- name: Python
  anchor: python
  category: client-driver
  owner: trinodb
  logo: /assets/images/logos/python.png
  logosmall: /assets/images/logos/python-small.png
  description: |
    Python is a programming language that lets you work quickly and integrate
    systems more effectively. Use the Trino Python Client to connect a Python
    script or application to a Trino cluster and receive the results of the
    submitted queries.
  links:
    - urltext: Python
      url: https://www.python.org/
    - urltext: trino-python-client
      url: https://github.com/trinodb/trino-python-client
    - urltext: Trino Community Broadcast 12 - Trino Python client and Apache Superset
      url: /episodes/12.html
- name: Querybook
  anchor: querybook
  category: client-application
  owner: other
  logo: /assets/images/logos/querybook.png
  logosmall: /assets/images/logos/querybook-small.png
  description: |
    Querybook is a browser-based data analysis tool that turns SQL queries into
    natural language reports and graphs called DataDocs. Querybook’s core focus
    is to make composing queries, creating analyses, and collaborating with
    others as simple as possible.
  links:
    - urltext: Querybook
      url: https://www.querybook.org/
    - urltext: Querybook with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/querybook.html
- name: Quix
  anchor: quix
  category: client-application
  owner: other
  logo: /assets/images/logos/quix.png
  logosmall: /assets/images/logos/quix-small.png
  description: |
    Quix is a multi-user, easy-to-use notebook manager.By utilizing Trino it
    provides unified access to multiple data sources and effectively acts as a
    shared space for your company's BI insights and know-how.
  links:
    - urltext: Quix
      url: https://wix-incubator.github.io/quix/
    - urltext: Documentation for Trino users
      url: https://wix-incubator.github.io/quix/docs/presto
- name: R
  anchor: r
  category: client-driver
  owner: other
  logo: /assets/images/logos/r.png
  logosmall: /assets/images/logos/r-small.png
  description: |
    R is a free software environment for statistical computing and graphics.
    RPresto is a DBI-based adapter for the open source distributed SQL query
    engines Presto and Trino for running interactive analytic queries.
  links:
    - urltext: R
      url: https://www.r-project.org/
    - urltext: RPresto
      url: https://github.com/prestodb/RPresto
- name: Redash
  anchor: redash
  category: client-application
  owner: other
  logo: /assets/images/logos/redash.png
  logosmall: /assets/images/logos/redash-small.png
  description: |
    Redash is a take on freeing the data within our company in a way that will
    better fit our culture and usage patterns. It has Trino support as well as
    other backends, and offers a query editor with syntax highlighting and
    completion, and creating visualizations and dashboards from query results.
  links:
    - urltext: Redash
      url: https://redash.io/
- name: Redis
  anchor: redis
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/redis.png
  logosmall: /assets/images/logos/redis-small.png
  description: |
    Redis is an open source, in-memory data store used by millions of developers
    as a database, cache, streaming engine, and message broker.

    Use a Redis data store as a data source in Trino by configuring a catalog
    with the Redis connector.
  links:
    - urltext: Redis
      url: https://redis.io/
    - urltext: MySQL connector documentation
      url: /docs/current/connector/redis.html
- name: Ruby
  anchor: ruby
  category: client-driver
  owner: other
  logo: /assets/images/logos/ruby.png
  logosmall: /assets/images/logos/ruby-small.png
  description: |
    Ruby is a dynamic, open source programming language with a focus on
    simplicity and productivity. Use the Trino Ruby client library to connect a
    Ruby script or application to a Trino cluster and receive the results of the
    submitted queries.
  links:
    - urltext: Ruby
      url: https://www.ruby-lang.org/en/
    - urltext: trino-client-ruby
      url: https://github.com/treasure-data/trino-client-ruby
- name: Rust
  anchor: rust
  category: client-driver
  owner: other
  logo: /assets/images/logos/rust.png
  logosmall: /assets/images/logos/rust-small.png
  description: |
    Rust is a programming language empowering everyone to build reliable and
    efficient software. Use the Prusto client library to connect a Rust
    application to a Trino cluster and receive the results of the submitted
    queries.
  links:
    - urltext: Rust
      url: https://www.rust-lang.org/
    - urltext: Prusto
      url: https://github.com/nooberfsh/prusto
- name: RudderStack
  anchor: rudderstack
  category: add-on
  owner: other
  logo: /assets/images/logos/rudderstack.png
  logosmall: /assets/images/logos/rudderstack-small.png
  description: |
    RudderStack provides a reverse ETL pipeline that supports Trino as a source. This
    integration makes it easy to sync data from Trino to over 200 destinations so
    every team can use it to drive better business outcomes. The integration
    supports warehouse-based diffing, making it the most performant reverse ETL
    solution for Trino.
  links:
    - urltext: RudderStack
      url: https://www.rudderstack.com/
    - urltext: Reverse ETL with Trino documentation
      url: https://www.rudderstack.com/docs/sources/reverse-etl/trino/
    - urltext: Annnouncement blog post
      url: https://www.rudderstack.com/blog/feature-launch-trino-reverse-etl-source/
- name: SingleStore
  anchor: singlestore
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/singlestore.png
  logosmall: /assets/images/logos/singlestore-small.png
  description: |
    SingleStoreDB is a unified data engine for transactional and analytical
    workloads, used to power fast, real-time analytics and applications.

    Use a SingleStore database as a data source in Trino by configuring a
    catalog with the SingleStore connector.
  links:
    - urltext: SingleStore
      url: https://www.singlestore.com/
    - urltext: SingleStore connector documentation
      url: /docs/current/connector/singlestore.html
- name: Snowflake
  anchor: snowflake
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/snowflake.png
  logosmall: /assets/images/logos/snowflake-small.png
  description: |
    Snowflake is a Data Cloud platform provider. Snowflake easily enables
    governed access to near-infinite amounts of data, cutting-edge tools,
    applications, and services. With the Data Cloud, you can collaborate locally
    and globally to reveal new insights, create previously unforeseen business
    opportunities, and identify and know your customers in the moment with
    seamless and relevant experiences.

    Use a Snowflake data cloud as a data source in Trino by configuring a
    catalog with the Snowflake connector.
  links:
    - urltext: Snowflake
      url: https://www.snowflake.com/
    - urltext: Snowflake connector documentation
      url: /docs/current/connector/snowflake.html
    - urltext: Let it snow for Trino presentation from Trino Fest 2023
      url: http://trino.io/blog/2023/07/12/trino-fest-2023-let-it-snow-recap.html
- name: SQL Formatter
  anchor: workload-analyzer
  category: add-on
  owner: other
  logo: /assets/images/logos/sql-formatter.png
  logosmall: /assets/images/logos/sql-formatter-small.png
  description: |
    SQL Formatter is a JavaScript library for pretty-printing SQL queries. It
    supports Trino and can be used as library for web applications, as command
    line tool, and with the live demo deployment. The project is also used for
    VS Code and vim extensions.
  links:
    - urltext: SQL Formatter documentation
      url: https://github.com/sql-formatter-org/sql-formatter/blob/master/README.md
    - urltext: SQL Formatter live demo
      url: https://sql-formatter-org.github.io/sql-formatter/
    - urltext: Documentation for supported languages including Trino
      url: https://github.com/sql-formatter-org/sql-formatter/blob/master/docs/language.md
- name: SQuirrel SQL
  anchor: squirrel-sql
  category: client-application
  owner: other
  logo: /assets/images/logos/squirrel-sql.png
  logosmall: /assets/images/logos/squirrel-sql-small.png
  description: |
    SQuirrel SQL is a Java-based graphical database client that allows you to
    view the structure of your database, browse the data in tables, and issue
    SQL commands. It uses JDBC to allow users to explore and interact with
    databases via a JDBC driver. In addition, it provides an editor that offers
    code completion and syntax highlighting for standard SQL.
  links:
    - urltext: SQuirrel SQL
      url: http://www.squirrelsql.org/
    - urltext: SQuirrel SQL with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/squirrel-sql.html
- name: Tableau
  anchor: tableau
  category: client-application
  owner: other
  logo: /assets/images/logos/tableau.png
  logosmall: /assets/images/logos/tableau-small.png
  description: |
    Tableau is a visual analytics platform transforming the way we use data to
    solve problems—empowering people and organizations to make the most of their
    data.
  links:
    - urltext: Tableau
      url: http://www.tableau.com/
    - urltext: How to connect Tableau to Trino
      url: https://help.tableau.com/current/pro/desktop/en-us/examples_presto.htm
- name: Testcontainers
  anchor: testcontainers
  category: add-on
  owner: other
  logo: /assets/images/logos/testcontainers.png
  logosmall: /assets/images/logos/testcontainers-small.png
  description: |
    Testcontainers is an open source framework for providing throwaway,
    lightweight instances of databases, message brokers, web browsers, or just
    about anything that can run in a Docker container.

    Use the Trino module in your integration tests and other scenarios.
  links:
    - urltext: Testcontainers
      url: https://testcontainers.com/
    - urltext: Trino module
      url: https://testcontainers.com/modules/trino/
- name: TPC
  anchor: tpc
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/tpc.png
  logosmall: /assets/images/logos/tpc-small.png
  description: |
    TPC is a non-profit corporation focused on developing data-centric benchmark
    standards and disseminating objective, verifiable data to the industry.

    The Trino TPC-H and TPC-DS connectors are data generators that provide the
    benchmark data sets for direct querying or copying into other data sources
    for testing and benchmarking.
  links:
    - urltext: TPC
      url: https://tpc.org/
    - urltext: TPC-DS connector documentation
      url: /docs/current/connector/tpcds.html
    - urltext: TPC-H connector documentation
      url: /docs/current/connector/tpch.html
- name: Trino-lb
  anchor: trino-lb
  category: add-on
  owner: other
  logo: /assets/images/logos/trino-lb.png
  logosmall: /assets/images/logos/trino-lb-small.png
  description: |
    Trino-lb is a load balancer with support for routing, queueing, and auto-scaling
    for multiple Trino clusters.
  links:
    - urltext: Trino-lb
      url: https://github.com/stackabletech/trino-lb
    - urltext: Trino-lb documentation
      url: https://github.com/stackabletech/trino-lb/blob/main/README.md
- name: Trino Gateway
  anchor: trino-gateway
  category: add-on
  owner: trinodb
  logo: /assets/images/logos/trino-gateway.png
  logosmall: /assets/images/logos/trino-gateway-small.png
  description: |
    Trino Gateway is a load balancer, proxy server, and configurable routing
    gateway for multiple Trino clusters. Users can register/de-register
    Trino clusters behind the gateway and connect to it using standard clients.
  links:
    - urltext: Trino Gateway
      url: https://trinodb.github.io/trino-gateway
    - urltext: Many clusters and only one gateway at Trino Summit 2023
      url: https://www.youtube.com/watch?v=2qwBcKmQSn0
    - urltext: Announcement blog post
      url: /blog/2023/09/28/trino-gateway
- name: Unity Catalog
  anchor: unity-catalog
  category: data-lake
  owner: trinodb
  logo: /assets/images/logos/unity-catalog.png
  logosmall: /assets/images/logos/unity-catalog-small.png
  description: |
    Unity Catalog is a unified governance solution for data and AI assets in the
    cloud. It provides a centralized metadata store, fine-grained access
    controls, and audit logging to help manage and secure your data. Unity
    Catalog simplifies data discovery, access, and sharing across your
    organization, ensuring compliance and enhancing collaboration.

    Use Unity Catalog with the Trino Delta Lake, Hive, or Iceberg connectors and
    the configuration for a Thrift metastore.
  links:
    - urltext: Unity Catalog
      url: https://www.unitycatalog.io/
    - urltext: Thrift metastore configuration properties
      url: /docs/current/object-storage/metastores.html#thrift-metastore-configuration-properties
- name: VAST
  anchor: vast
  category: data-source
  owner: other
  logo: /assets/images/logos/vast.png
  logosmall: /assets/images/logos/vast-small.png
  description: |
    VAST is a data platform that includes storage and database services.

    Use a VAST data store as a data source in Trino by configuring a
    catalog with the VAST Trino connector.
  links:
    - urltext: VAST
      url: https://vastdata.com/
    - urltext: VAST Trino connector
      url: https://github.com/vast-data/vast-trino-connector
    - urltext: VAST database catalog at Trino Summit 2023
      url: https://www.youtube.com/watch?v=RutbCY8i22Q
    - urltext: Trino Community Broadcast 56 - The vast possibilities of VAST and Trino
      url: /episodes/56.html
- name: Vertica
  anchor: vertica
  category: data-source
  owner: trinodb
  logo: /assets/images/logos/vertica.png
  logosmall: /assets/images/logos/vertica-small.png
  description: |
    Vertica, also known as the OpenText Analytics Database, is a column-oriented
    analytic database designed to manage large, fast-growing volumes of data, with
    fast query perfomacne for data warehouses and other query-intensive applications.

    Use a Vertica database as a data source in Trino by configuring a  catalog with the 
    Vertica connector.
  links:
    - urltext: Vertica
      url:  https://www.opentext.com/products/analytics-database
    - urltext: Vertica connector documentation
      url: /docs/current/connector/vertica.html
- name: VSCode
  anchor: vscode
  category: client-application
  owner: other
  logo: /assets/images/logos/vscode.png
  logosmall: /assets/images/logos/vscode-small.png
  description: |
    Visual Studio Code (VSCode) is a free, open-source editor by Microsoft
    with features such as syntax highlighting, IntelliSense, code navigation,
    and built-in debugging for developers. With extensions it can also work as
    a SQL client.
  links:
    - urltext: Visual Studio Code
      url:  https://code.visualstudio.com/
    - urltext: sqltools-trino-driver
      url: https://github.com/regadas/sqltools-trino-driver
- name: waii
  anchor: waii
  category: client-application
  owner: other
  logo: /assets/images/logos/waii.png
  logosmall: /assets/images/logos/waii-small.png
  description: |
    Waii helps you build more intuitive data products and applications with the
    world's most accurate text-to-sql, text-to-chart, and conversational
    business intelligence APIs.
  links:
    - urltext: waii
      url:  https://www.waii.ai/
    - urltext: Tutorial for using waii with Trino
      url: https://doc.waii.ai/deployment/docs/trino-onboarding
    - urltext: Waii participating in AI panel at Trino Summit 2024
      url: https://www.youtube.com/watch?v=gobl6PhIWeE
- name: Workload Analyzer
  anchor: workload-analyzer
  category: add-on
  owner: other
  logo: /assets/images/logos/workload-analyzer.png
  logosmall: /assets/images/logos/workload-analyzer-small.png
  description: |
    The Workload Analyzer collects Trino workload statistics, and analyzes them.
    The resulting report provides improved visibility into your analytical
    workloads, and enables cluster performance optimization.
  links:
    - urltext: Workload analyzer
      url: https://github.com/varadaio/presto-workload-analyzer
    - urltext: Installation instructions
      url: https://github.com/varadaio/presto-workload-analyzer/blob/main/INSTALL.md
- name: Wren AI
  anchor: wren-ai
  category: client-application
  owner: other
  logo: /assets/images/logos/wren-ai.png
  logosmall: /assets/images/logos/wren-ai-small.png
  description: |
    Wren AI is a SQL AI Agent for data teams to get results and insights faster by
    asking business questions without writing SQL.
  links:
    - urltext: Wren AI
      url:  https://www.getwren.ai/
    - urltext: Trino as Wren AI data source
      url: https://docs.getwren.ai/oss/guide/connect/trino
    - urltext: Wren AI participating in AI panel at Trino Summit 2024
      url: https://www.youtube.com/watch?v=gobl6PhIWeE
    - urltext: Trino Community Broadcast 66 about Wren AI and Trino
      url: /episodes/66.html
- name: yanagishima
  anchor: yanagishima
  category: client-application
  owner: other
  logo: /assets/images/logos/yanagishima.png
  logosmall: /assets/images/logos/yanagishima-small.png
  description: |
    yanagishima is a web application for Trino. yanagishima provides the ability
    to execute query, show query, kill query, bookmark query, search table,
    share query/query result, format query, download as CSV/TSV file, insert
    chart, substitute query parameter, and so on.
  links:
    - urltext: yanagishima
      url: https://yanagishima.github.io/yanagishima/
- name: Zing Data
  anchor: zing-data
  category: client-application
  owner: other
  logo: /assets/images/logos/zing-data.png
  logosmall: /assets/images/logos/zing-data-small.png
  description: |
    Zing Data is a data analysis and collaboration platform with native apps on
    iOS, Android, and the web. Zing makes asking questions of data and
    visualizing answers easy for everybody in your organization. Free for small
    teams, and super-affordable for bigger ones, Zing requires no SQL, no
    desktop, and no instruction manual. Collaborate as easily as chatting, and
    integrate seamlessly with all the data sources you already have.
  links:
    - urltext: Zing Data
      url: https://getzingdata.com/
    - urltext: Set up Trino as a data source
      url: https://docs.getzingdata.com/docs/setting-up-a-data-source/trino_setup/
    - urltext: Zing Data with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/zingdata.html
