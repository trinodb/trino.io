################################################################################
# Data for the display on the detailed ecosystem pages
################################################################################
- name: Alluxio
  anchor: alluxio
  category: add-on
  logo: /assets/images/logos/alluxio.png
  logosmall: /assets/images/logos/alluxio-small.png
  description: |
    Alluxio provides a single pane of glass for enterprises to manage data and
    AI workloads across diverse infrastructure environments with ease. Alluxio
    Data Platform has two product offerings, Alluxio Enterprise Data and Alluxio
    Enterprise AI.

    Alluxio provides an open source object storage caching solution that is the
    base of the file system cache support in Trino. The commercial platform with
    its distributed block-level read/write caching functionality can be used for
    further integration.
  links:
    - urltext: Alluxio
      url: https://www.alluxio.io/
    - urltext: Interactive analytics with Trino and Alluxio product information
      url: https://www.alluxio.io/trino/
    - urltext: Trino file system cache documentation
      url: https://trino.io/docs/current/object-storage/file-system-cache.html
    - urltext: Documentation for Alluxio platform with Trino
      url: https://docs.alluxio.io/ee/user/stable/en/compute/Trino.html
- name: Amazon Kinesis
  anchor: amazon-kinesis
  category: data-source
  logo: /assets/images/logos/amazon-kinesis.png
  logosmall: /assets/images/logos/amazon-kinesis-small.png
  description: |
    Amazon Kinesis cost-effectively processes and analyzes streaming data at any
    scale as a fully managed service. With Kinesis, you can ingest real-time
    data, such as video, audio, application logs, website clickstreams, and IoT
    telemetry data, for machine learning (ML), analytics, and other
    applications.

    Use an Amazon Kinesis stream as a data source in Trino by configuring a
    catalog with the Kinesis connector.
  links:
    - urltext: Amazon Kinesis
      url: https://aws.amazon.com/kinesis/
    - urltext: Kinesis connector documentation
      url: https://trino.io/docs/current/connector/kinesis.html
- name: Amazon Redshift
  anchor: amazon-redshift
  category: data-source
  logo: /assets/images/logos/amazon-redshift.png
  logosmall: /assets/images/logos/amazon-redshift-small.png
  description: |
    Amazon Redshift uses SQL to analyze structured and semi-structured data
    across data warehouses, operational databases, and data lakes, using
    AWS-designed hardware and machine learning to deliver the best price
    performance at any scale.

    Use an Amazon Redshift data warehouse as a data source in Trino by
    configuring a catalog with the Redshift connector.
  links:
    - urltext: Amazon Redshift
      url: https://aws.amazon.com/redshift/
    - urltext: Redshift connector documentation
      url: https://trino.io/docs/current/connector/redshift.html
- name: Apache Accumulo
  anchor: apache-accumulo
  category: data-source
  logo: /assets/images/logos/apache-accumulo.png
  logosmall: /assets/images/logos/apache-accumulo-small.png
  description: |
    Apache Accumulo® is a sorted, distributed key-value store that provides
    robust, scalable data storage and retrieval.

    Use an Apache Accumulo key-value store as a data source in Trino by
    configuring a catalog with the Accumulo connector.
  links:
    - urltext: Apache Accumulo
      url: https://accumulo.apache.org/
    - urltext: Accumulo connector documentation
      url: https://trino.io/docs/current/connector/accumulo.html
- name: Apache Airflow
  anchor: apache-airflow
  category: client
  logo: /assets/images/logos/airflow.png
  logosmall: /assets/images/logos/airflow-small.png
  description: |
    Airflow™ is a platform created by the community to programmatically author,
    schedule, and monitor workflows.
  links:
    - urltext: Apache Airflow
      url: https://airflow.apache.org/
    - urltext: Trino provider for Apache Airflow
      url: https://airflow.apache.org/docs/apache-airflow-providers-trino/stable/index.html
    - urltext: Using Trino with Apache Airflow for (almost) all your data
        problems from Trino Summit 2022
      url: /blog/2022/12/21/trino-summit-2022-astronomer-recap.html
- name: Apache Cassandra
  anchor: apache-cassandra
  category: data-source
  logo: /assets/images/logos/apache-cassandra.png
  logosmall: /assets/images/logos/apache-cassandra-small.png
  description: |
    Apache Cassandra is an open source NoSQL distributed database trusted by
    thousands of companies for scalability and high availability without
    compromising performance. Linear scalability and proven fault-tolerance on
    commodity hardware or cloud infrastructure make it the perfect platform for
    mission-critical data.

    Use an Apache Cassandra database as a data source in Trino by configuring a
    catalog with the Cassandra connector.
  links:
    - urltext: Apache Cassandra
      url: https://cassandra.apache.org/
    - urltext: Cassandra connector documentation
      url: https://trino.io/docs/current/connector/cassandra.html
- name: Apache DolphinScheduler
  anchor: apache-dolphinscheduler
  category: client
  logo: /assets/images/logos/apache-dolphinscheduler.png
  logosmall: /assets/images/logos/apache-dolphinscheduler-small.png
  description: |
    Apache DolphinScheduler is an open-source, distributed workflow scheduling
    platform designed to manage and execute batch jobs, data pipelines, and ETL
    processes. DolphinScheduler enables users to create and manage consecutive
    jobs run easily, including support for different types of tasks, such as SQL
    statements, shell scripts, Spark jobs, Kubernetes deployments, and many
    others.
  links:
    - urltext: Apache DolphinScheduler
      url: https://dolphinscheduler.apache.org/
    - urltext: Trino swimming with the DolphinScheduler from Trino Community
        Broadcast 45
      url: https://trino.io/episodes/45.html
- name: Apache Druid
  anchor: apache-druid
  category: data-source
  logo: /assets/images/logos/apache-druid.png
  logosmall: /assets/images/logos/apache-druid-small.png
  description: |
    Druid is a high performance, in-memory, real-time analytics database that
    delivers sub-second queries on streaming and batch data at scale and under
    load.

    Use an Apache Druid database as a data source in Trino by configuring a
    catalog with the Druid connector.
  links:
    - urltext: Apache Druid
      url: https://druid.apache.org/
    - urltext: Druid connector documentation
      url: https://trino.io/docs/current/connector/druid.html
    - urltext: Make data fluid with Apache Druid from Trino Community Broadcast
        16
      url: https://trino.io/episodes/16.html
- name: Apache Hive
  anchor: apache-hive
  category: data-source
  logo: /assets/images/logos/apache-hive.png
  logosmall: /assets/images/logos/apache-hive-small.png
  description: |
    Apache Hive is a distributed, fault-tolerant data warehouse system that
    enables analytics at a massive scale and facilitates reading, writing, and
    managing petabytes of data residing in distributed storage using SQL.

    Use an Apache Hive data warehouse as a data source in Trino by configuring a
    catalog with the Hive connector.
  links:
    - urltext: Apache Hive
      url: https://hive.apache.org/
    - urltext: Hive connector documentation
      url: https://trino.io/docs/current/connector/hive.html
    - urltext: What is Trino and the Hive connector from Trino Community
        Broadcast 29
      url: https://trino.io/episodes/29.html
- name: Apache Hudi
  anchor: apache-hudi
  category: data-source
  logo: /assets/images/logos/apache-hudi.png
  logosmall: /assets/images/logos/apache-hudi-small.png
  description: |
    Apache Hudi is a transactional data lake platform that brings database and
    data warehouse capabilities to the data lake. Hudi reimagines slow
    old-school batch data processing with a powerful new incremental processing
    framework for low latency minute-level analytics.

    Use an Apache Hudi data lake as a data source in Trino by configuring a
    catalog with the Hudi connector.
  links:
    - urltext: Apache Hudi
      url: https://hudi.apache.org/
    - urltext: Hudi connector documentation
      url: https://trino.io/docs/current/connector/hudi.html
    - urltext: Interview with Hudi contributors from Trino Community Broadcast 
        41
      url: https://trino.io/episodes/41.html
- name: Apache Iceberg
  anchor: apache-iceberg
  category: data-source
  logo: /assets/images/logos/apache-iceberg.png
  logosmall: /assets/images/logos/apache-iceberg-small.png
  description: |
    Apache Iceberg is a high-performance format for huge analytic tables.
    Iceberg brings the reliability and simplicity of SQL tables to big data,
    while making it possible for engines like Spark, Trino, Flink, Presto, Hive
    and Impala to safely work with the same tables, at the same time.

    Use an Apache Iceberg data lakehouse as a data source in Trino by
    configuring a catalog with the Iceberg connector.
  links:
    - urltext: Apache Iceberg
      url: https://iceberg.apache.org/
    - urltext: Iceberg connector documentation
      url: https://trino.io/docs/current/connector/iceberg.html
    - urltext: Interview with Iceberg creator from Trino Community Broadcast 40
      url: https://trino.io/episodes/40.html
# there are lots more from Trino Fest, Trino Summot .. need to figure out how many we are happy to have.. 
- name: Apache Ignite
  anchor: apache-ignite
  category: data-source
  logo: /assets/images/logos/apache-ignite.png
  logosmall: /assets/images/logos/apache-ignite-small.png
  description: |
    Apache Ignite is a distributed in‑memory database for high‑performance
    applications. It scales across memory, disk, and multiple machines without
    compromise.

    Use an Apache Ignite database as a data source in Trino by configuring a
    catalog with the Apache Ignite connector.
  links:
    - urltext: Apache Ignite
      url: https://ignite.apache.org/
    - urltext: Ignite connector documentation
      url: https://trino.io/docs/current/connector/ignite.html
    - urltext: Interview about the Ignite connector from Trino Community
        Broadcast 46
      url: https://trino.io/episodes/46.html
- name: Apache Kafka
  anchor: apache-kafka
  category: data-source
  logo: /assets/images/logos/apache-kafka.png
  logosmall: /assets/images/logos/apache-kafka-small.png
  description: |
    Apache Kafka is an open source distributed event streaming platform used by
    thousands of companies for high-performance data pipelines, streaming
    analytics, data integration, and mission-critical applications.

    Use an Apache Kafka event stream as a data source in Trino by configuring a
    catalog with the Kafka connector.
  links:
    - urltext: Apache Kafka
      url: https://kafka.apache.org/
    - urltext: Kafka connector documentation
      url: https://trino.io/docs/current/connector/kafka.html
- name: Apache Kudu
  anchor: apache-kudu
  category: data-source
  logo: /assets/images/logos/apache-kudu.png
  logosmall: /assets/images/logos/apache-kudu-small.png
  description: |
    Apache Kudu is an open source distributed data storage engine that makes
    fast analytics on fast and changing data easy.

    Use an Apache Kudu data storage as a data source in Trino by configuring a
    catalog with the Kudu connector.
  links:
    - urltext: Apache Kudu
      url: https://kudu.apache.org/
    - urltext: Kudu connector documentation
      url: https://trino.io/docs/current/connector/kudu.html
- name: Apache Phoenix
  anchor: apache-phoenix
  category: data-source
  logo: /assets/images/logos/apache-phoenix.png
  logosmall: /assets/images/logos/apache-phoenix-small.png
  description: |
    Apache Phoenix enables OLTP and operational analytics in Hadoop for low
    latency applications by combining the best of both worlds:

    * The power of standard SQL and JDBC APIs with full ACID transaction
      capabilities and
    * The flexibility of late-bound, schema-on-read
      capabilities from the NoSQL world by leveraging HBase as its backing store

    Use a Apache Phoenix key value store as a data source in Trino by
    configuring a catalog with the Phoenix connector.
  links:
    - urltext: Apache Phoenix
      url: https://phoenix.apache.org/
    - urltext: Phoenix connector documentation
      url: https://trino.io/docs/current/connector/phoenix.html
- name: Apache Pinot
  anchor: apache-pinot
  category: data-source
  logo: /assets/images/logos/apache-pinot.png
  logosmall: /assets/images/logos/apache-pinot-small.png
  description: |
    Apache Pinot is a real-time distributed OLAP datastore, designed to answer
    OLAP queries with low latency

    Use an Apache Pinot datastore as a data source in Trino by configuring a
    catalog with the Pinot connector.
  links:
    - urltext: Apache Pinot
      url: https://pinot.apache.org/
    - urltext: Pinot connector documentation
      url: https://trino.io/docs/current/connector/pinot.html
    - urltext: Trino takes a sip of Pinot! from Trino Community Broadcast 13
      url: https://trino.io/episodes/13.html
- name: Apache Superset
  anchor: apache-superset
  category: client
  logo: /assets/images/logos/superset.png
  logosmall: /assets/images/logos/superset-small.png
  description: |
    Apache Superset enables users to consume data in many different ways:
    writing SQL queries, creating new tables, creating a visualization
    (slice), adding that visualization to one or many dashboards and
    downloading a CSV. SQL Lab is a a part of Superset and provides a rich
    SQL editor that enables users to both query and visualize data. You
    can explore and preview tables in Trino, effortlessly compose SQL
    queries to access data. From there, you can either export a CSV file
    or immediately visualize your data in the Superset "Explore" view.
  links:
    - urltext: Apache Superset
      url: https://superset.apache.org/
    - urltext: Apache Superset - Trino configuration
      url: https://superset.apache.org/docs/databases/trino
    - urltext: Tutorial
      url: https://docs.starburst.io/data-consumer/clients/superset.html
    - urltext: Visualizing Trino with Apache Superset at Trino Summit 2023
      url: https://www.youtube.com/watch?v=idk0GMxs8vE
    - urltext: Trino gets super visual with Apache Superset! from Trino
        Community Broadcast 12
      url: https://trino.io/episodes/12.html
- name: CLI
  anchor: cli
  category: client
  logo: /assets/images/logos/cli.png
  logosmall: /assets/images/logos/cli-small.png
  description: |
    The Trino CLI is a feature-rich command line interface tool for interactive
    query processing with Trino. The batch mode allows you to integrate the CLI
    with any other processing and automation that supports command line
    interactions.
  links:
    - urltext: Trino CLI documentation and download
      url: https://trino.io/docs/current/client/cli.html
    - urltext: User guide
      url: https://docs.starburst.io/data-consumer/clients/cli.html
- name: Clickhouse
  anchor: clickhouse
  category: data-source
  logo: /assets/images/logos/clickhouse.png
  logosmall: /assets/images/logos/clickhouse-small.png
  description: |
    ClickHouse is the fastest and most resource efficient open source real-time
    database for applications and analytics.

    Use a Clickhouse database as a data source in Trino by configuring a catalog
    with the Clickhouse connector.
  links:
    - urltext: Clickhouse
      url: https://clickhouse.com/
    - urltext: Clickhouse connector documentation
      url: https://trino.io/docs/current/connector/clickhouse.html
- name: Coginiti
  anchor: coginiti
  category: client
  logo: /assets/images/logos/coginiti.png
  logosmall: /assets/images/logos/coginiti-small.png
  description: |
    Coginiti offers a comprehensive solution for data professionals, integrating
    essential functionalities such as modular development, version control,
    feedback mechanisms, testing capabilities, and documentation tools. By
    leveraging these features, analysts and data engineers can improve analytic
    consistency, increase productivity, and expedite the delivery of valuable
    insights.

    Unlock a new data analytics paradigm with Coginiti’s full support for Trino,
    a game-changer in large-scale data querying.
  links:
    - urltext: Coginiti
      url: https://www.coginiti.co
    - urltext: Coginiti as enterprise SQL workspace for Trino
      url: https://www.coginiti.co/databases/trino/
    - urltext: Interview and demo with Coginiti from Trino Community Broadcast 53
      url: https://trino.io/episodes/53.html
- name: Cube
  anchor: cube
  category: client
  logo: /assets/images/logos/cube.png
  logosmall: /assets/images/logos/cube-small.png
  description: |
    Cube is headless BI for building data apps. You can use Cube to create an
    additional semantic layer or a last-mile caching layer on top of Trino. More
    importantly, you can use the set of APIs that Cube provides, including REST
    API, GraphQL API, and SQL API, to deliver the data directly to custom-built
    front-end applications as well as BI tools and notebooks, retaining low
    latency and high concurrency.
  links:
    - urltext: Cube
      url: https://cube.dev/
    - urltext: Trino as data source with Cube
      url: https://cube.dev/integrations/Trino-Data-API
    - urltext: Announcement blog post
      url: https://cube.dev/blog/cube-integration-with-trino-sql-query-engine-for-big-data
- name: Datadog
  anchor: datadog
  category: add-on
  logo: /assets/images/logos/datadog.png
  logosmall: /assets/images/logos/datadog-small.png
  description: |
    The Datadog integration allows the observability service for cloud-scale
    applications to monitor your Trino cluster. It accesses the [JMX metrics
    provided by Trino](/docs/current/admin/jmx.html), and exposes them in
    Datadog for monitoring, inspection, and troubleshooting purposes.
  links:
    - urltext: Datadog
      url: https://www.datadoghq.com/
    - urltext: Documentation for Trino integration
      url: https://docs.datadoghq.com/integrations/trino/
- name: DBeaver
  anchor: DBeaver
  category: client
  logo: /assets/images/logos/dbeaver.png
  logosmall: /assets/images/logos/dbeaver-small.png
  description: |
      DBeaver is a cross-platform database tool for developers, database
      administrators, analysts, and everyone working with data. With DBeaver you
      are able to manipulate with your data like in a regular spreadsheet,
      create analytical reports based on records from different data storages,
      export information in an appropriate format. For advanced database users
      DBeaver suggests a powerful SQL-editor, plenty of administration features,
      abilities of data and schema migration, monitoring database connection
      sessions, and a lot more.

      It is avaiable as free open source DBeaver Community and as various
      commercially supported DBeaver PRO editions. A web application version
      called CloudBeaver is also available. All editions support many databases,
      including Trino.
  links:
    - urltext: DBeaver Community
      url: https://dbeaver.io/
    - urltext: DBeaver PRO
      url: https://dbeaver.com/
    - urltext: CloudBeaver
      url: https://dbeaver.com/docs/cloudbeaver/
    - urltext: DBeaver and Trino guide
      url: https://docs.starburst.io/data-consumer/clients/dbeaver.html
- name: dbt
  anchor: dbt
  category: client
  logo: /assets/images/logos/dbt.png
  logosmall: /assets/images/logos/dbt-small.png
  description: |
    dbt is a transformation workflow that helps you get more work done while
    producing higher quality results. You can use dbt to modularize and
    centralize your analytics code, while also providing your data team with
    guardrails typically found in software engineering workflows. Collaborate on
    data models, version them, and test and document your queries before safely
    deploying them to production, with monitoring and visibility.
  links:
    - urltext: dbt
      url: https://www.getdbt.com/
    - urltext: dbt documentation
      url: https://docs.getdbt.com/
    - urltext: dbt configuration for Trino
      url: https://docs.getdbt.com/reference/resource-configs/trino-configs
    - urltext: dbt-trino plugin
      url: https://github.com/starburstdata/dbt-trino
    - urltext: Interview with dbt developers from Trino Community Broadcast 30
      url: https://trino.io/episodes/30.html
    - urltext: Introduction to dbt and Trino from Trino Community Broadcast 21
      url: https://trino.io/episodes/21.html
- name: Delta Lake
  anchor: delta-lake
  category: data-source
  logo: /assets/images/logos/delta-lake.png
  logosmall: /assets/images/logos/delta-lake-small.png
  description: |
    Delta Lake is an open source storage framework that enables building a
    Lakehouse architecture with compute engines including Spark, PrestoDB,
    Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.

    Use a Delta Lake data lakehouse as a data source in Trino by configuring a
    catalog with the Delta Lake connector.
  links:
    - urltext: Delta Lake
      url: https://delta.io/
    - urltext: Delta Lake connector documentation
      url: https://trino.io/docs/current/connector/delta-lake.html
    - urltext: Interview about new Delta Lake connector from Trino Community
        Broadcast 34
      url: https://trino.io/episodes/34.html
- name: Elasticsearch
  anchor: elasticsearch
  category: data-source
  logo: /assets/images/logos/elasticsearch.png
  logosmall: /assets/images/logos/elasticsearch-small.png
  description: |
    Elasticsearch is a distributed, RESTful search and analytics engine capable
    of addressing a growing number of use cases. As the heart of the Elastic
    Stack, it centrally stores your data for lightning fast search, fine‑tuned
    relevancy, and powerful analytics that scale with ease.

    Use an Elasticsearch index as a data source in Trino by configuring a
    catalog with the Elasticsearch connector.
  links:
    - urltext: Elasticsearch
      url: https://www.elastic.co/elasticsearch/
    - urltext: Elasticsearch connector documentation
      url: https://trino.io/docs/current/connector/elasticsearch.html
- name: Emacs
  anchor: emacs
  category: client
  logo: /assets/images/logos/emacs.png
  logosmall: /assets/images/logos/emacs-small.png
  description: |
    GNU Emacs, a versatile and extensible text editor, offers support for
    numerous programming languages and tools, including SQL. If you're
    interested in using Emacs to work with SQL databases, the built-in sql-mode
    and sql-interactive-mode are your friends. To use it with Trino include the
    sql-trino.el mode.
  links:
    - urltext: GNU Emacs
      url: https://www.gnu.org/software/emacs/
    - urltext: sql-trino.el
      url: https://github.com/regadas/sql-trino
- name: FugueSQL
  anchor: fugue-sql
  category: client
  logo: /assets/images/logos/fuguesql.png
  logosmall: /assets/images/logos/fuguesql-small.png
  description: |
    Fugue provides an easier interface to using distributed compute effectively
    and accelerates big data projects. It does this by minimizing the amount of
    code you need to write, in addition to taking care of tricks and
    optimizations that lead to more efficient execution on distrubted compute.
    Fugue ports Python, Pandas, and SQL code to Spark, Dask, and Ray, and
    supports Trino.
  links:
    - urltext: FugueSQL
      url: https://fugue-tutorials.readthedocs.io/index.html
    - urltext: Fugue with Trino documentation
      url: https://fugue-tutorials.readthedocs.io/tutorials/integrations/warehouses/trino.html
    - urltext: Interoperable Python and Trino for interactive workloads
        from TrinoFest 2023
      url: https://trino.io/blog/2023/07/27/trino-fest-2023-fugue-recap
- name:  Git
  anchor: git
  category: data-source
  logo: /assets/images/logos/git.png
  logosmall: /assets/images/logos/git-small.png
  description: |
    Git is a free and open source distributed version control system designed to
    handle everything from small to very large projects with speed and
    efficiency.

    Use a git repository as a data source in Trino by configuring a catalog with
    the git connector.
  links:
    - urltext: Git
      url: https://git-scm.com/
    - urltext: Trino git connector
      url: https://github.com/nineinchnick/trino-git
- name: Go
  anchor: go
  category: client
  logo: /assets/images/logos/go.png
  logosmall: /assets/images/logos/go-small.png
  description: |
    Go is a statically typed, compiled high-level programming language. Use the
    Trino Go client to connect a Go applications to a Trino cluster and receive
    the results of the submitted SQL queries.
  links:
    - urltext: Go
      url: https://go.dev/
    - urltext: Trino Go client source code and documentation
      url: https://github.com/trinodb/trino-go-client
- name: Google BigQuery
  anchor: google-bigquery
  category: data-source
  logo: /assets/images/logos/google-bigquery.png
  logosmall: /assets/images/logos/google-bigquerye-small.png
  description: |
    BigQuery is a serverless and cost-effective enterprise data warehouse that
    works across clouds and scales with your data. Use built-in ML/AI and BI for
    insights at scale.

    Use a Google BigQuery data warehouse as a data source in Trino by
    configuring a catalog with the BigQuery connector.
  links:
    - urltext: Google BigQuery
      url: https://cloud.google.com/bigquery/
    - urltext: BigQuery connector documentation
      url: https://trino.io/docs/current/connector/bigquery.html
- name: Google Sheets
  anchor: google-sheets
  category: data-source
  logo: /assets/images/logos/google-sheets.png
  logosmall: /assets/images/logos/google-sheets-small.png
  description: |
    Google Sheets enables you to ceate and collaborate on online spreadsheets
    in real-time and from any device.

    Use a Google Sheets spreadsheet as a data source in Trino by configuring a
    catalog with the Google Sheets connector.
  links:
    - urltext: Google Sheets
      url: https://www.google.com/sheets/about/
    - urltext: Google Sheets connector documentation
      url: https://trino.io/docs/current/connector/googlesheets.html
- name: Grafana
  anchor: grafana
  category: client
  logo: /assets/images/logos/grafana.png
  logosmall: /assets/images/logos/grafana-small.png
  description: |
    Grafana is a multi-platform open source analytics and interactive
    visualization web application. It provides charts, graphs, and alerts for
    the web when connected to supported data sources.

    The Trino Grafana Data Source Plugin allows you to connect your Grafana
    dashboards to Trino and use the configured catalogs as data source.
  links:
    - urltext: Grafana
      url: https://grafana.com/
    - urltext: Trino Grafana Data Source Plugin
      url: https://github.com/trinodb/grafana-trino
- name: Gravitino
  anchor: gravitino
  category: data-source
  logo: /assets/images/logos/gravitino.png
  logosmall: /assets/images/logos/gravitino-small.png
  description: |
    Gravitino is a high-performance, geo-distributed, and federated metadata
    lake. It manages the metadata directly in different sources, types, and
    regions. It also provides users with unified metadata access for data and AI
    assets, and is available as an open source project.

    Use Gravitino as a data source in Trino by configuring a catalog with the
    Gravitino connector.
  links:
    - urltext: Gravitino
      url: https://datastrato.ai/gravitino/
    - urltext: Gravitino Trino connector documentation
      url: https://datastrato.ai/docs/0.4.0/trino-connector/index
- name: Great Expectations
  anchor: great-expectations
  category: client
  logo: /assets/images/logos/great-expectations.png
  logosmall: /assets/images/logos/great-expectations-small.png
  description: |
    Great Expectations is the leading tool for validating, documenting, and
    profiling your data to maintain quality and improve communication between
    teams.
  links:
    - urltext: Great Expectations
      url: https://greatexpectations.io
    - urltext: Great Expectations documentation
      url: https://docs.greatexpectations.io/
    - urltext: Trino guide
      url: https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/database/trino/
    - urltext: Make your Trino data pipelines production ready with Great 
        Expectations
      url: https://trino.io/blog/2022/08/24/data-pipelines-production-ready-great-expectations.html
- name: Harlequin
  anchor: Harlequin
  category: client
  logo: /assets/images/logos/harlequin.png
  logosmall: /assets/images/logos/harlequin-small.png
  description: |
      Harlequin is a portable, powerful, colorful, easy, fast, and beautiful
      database client for the terminal. It runs on any shell, any terminal, and
      any machine.

      Harlequin is free to download and you install it with `pipx` or `pip` and
      the command `install harlequin_trino`.
  links:
    - urltext: Harlequin
      url: https://harlequin.sh/
    - urltext: Harlequin Trino adapter
      url: https://harlequin.sh/docs/trino/index
- name: Hue
  anchor: hue
  category: client
  logo: /assets/images/logos/hue.png
  logosmall: /assets/images/logos/hue-small.png
  description: |
    Hue is a mature open source SQL assistant for querying databases and data
    warehouses. It is used by Fortune 500 companies, and focused on smart query
    typing.
  links:
    - urltext: Hue
      url: http://gethue.com/
    - urltext: Instructions to use the Trino connector
      url: https://docs.gethue.com/administrator/configuration/connectors/#trino
- name: Ibis
  anchor: ibis
  category: client
  logo: /assets/images/logos/ibis.png
  logosmall: /assets/images/logos/ibis-small.png
  description: |
    Ibis is a dataframe interface to execution engines with support for 15+
    backends, including Trino. Ibis doesn’t replace your existing execution
    engine, it extends it with powerful abstractions and intuitive syntax. For
    those who love doing all their data-related work in Python, this allows you
    to write Python code that leverages the speed and power of Trino without
    needing to become a SQL master.
  links:
    - urltext: Ibis Project
      url: https://ibis-project.org/
    - urltext: Trino as Ibis backend
      url: https://ibis-project.org/backends/trino/
    - urltext: Because SQL is everywhere and so is Python from TrinoFest 2023
      url: https://trino.io/blog/2023/07/03/trino-fest-2023-ibis.html
    - urltext: Trino, Ibis, and wrangling Python in the SQL ecosystem from Trino
        Community Broadcast 49
      url: https://trino.io/episodes/49.html
- name: IBM Cognos Analytics
  anchor: ibm-cognos-analytics
  category: client
  logo: /assets/images/logos/ibm-cognos-analytics.png
  logosmall: /assets/images/logos/ibm-cognos-analytics-small.png
  description: |
    Cognos Analytics is a comprehensive business intelligence and performance
    management suite providing robust reporting, dashboards, data modeling and
    real-time monitoring, score carding, and predictive analytics. Cognos
    Analytics aims to empower users to collaborate, plan, and make smart
    decisions for better business results.
  links:
    - urltext: IBM Cognos Analytics
      url: https://www.ibm.com/products/cognos-analytics
    - urltext: List of supported software, including Trino versions
      url: https://www.ibm.com/support/pages/node/6966712
- name: JavaScript
  anchor: javascript
  category: client
  logo: /assets/images/logos/javascript.png
  logosmall: /assets/images/logos/javascript-small.png
  description: |
    Applications using JavaScript, TypeScript, Node.js, and related
    frameworks can use the trino-js-client, presto-client-node, or lento projects
    to connect to a Trino cluster and receive the results of the submitted
    queries.
  links:
    - urltext: trino-js-client
      url: https://github.com/regadas/trino-js-client
    - urltext: presto-client-node
      url: https://github.com/tagomoris/presto-client-node
    - urltext: lento
      url: https://github.com/vweevers/lento
- name: JDBC
  anchor: jdbc
  category: client
  logo: /assets/images/logos/jdbc.png
  logosmall: /assets/images/logos/jdbc-small.png
  description: |
    Java Database Connectivity (JDBC) enables applications running on the JVM to
    connect and query databases. Use the Trino JDBC driver with your application
    for the JVM, written in Java, Kotlin, or any other JVM language, or provided
    by your tool vendor.
  links:
    - urltext: Trino JDBC Driver documentation
      url: https://trino.io/docs/current/client/jdbc.html
- name: JetBrains Datagrip
  anchor: jetbrains-datagriop
  category: client
  logo: /assets/images/logos/datagrip.png
  logosmall: /assets/images/logos/datagrip-small.png
  description: |
    DataGrip by JetBrains is an IDE for databases that is tailored to suit the
    specific needs of professional SQL developers. It is designed to work with
    databases installed locally, on a server, or in the cloud. It is installed
    as a local application on your workstation.
  links:
    - urltext: JetBrains Datagrip
      url: https://www.jetbrains.com/datagrip/
    - urltext: Datagrip with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/datagrip.html
- name: JMX
  anchor: jmx
  category: add-on
  logo: /assets/images/logos/jmx.png
  logosmall: /assets/images/logos/jmx-small.png
  description: |
    Java Management Extensions (JMX) is a Java technology that supplies tools
    for managing and monitoring applications, system objects, devices (such as
    printers) and service-oriented networks. It defines a management
    architecture, design patterns, APIs, and services for building web-based,
    distributed, dynamic, and modular solutions to manage Java-enabled
    resources.

    Trino exposes numerous metrics for JMX. The metrics can be
    inspected and monitored with external JMX application, and in Trino itself
    with SQL statements and the included JMX connector.
  links:
    - urltext: JMX
      url: https://www.oracle.com/technical-resources/articles/javase/jmx.html
    - urltext: Monitoring with JMX
      url: https://trino.io/docs/current/admin/jmx.html
    - urltext: JMX connector
      url: https://trino.io/docs/current/connector/jmx.html
- name: jOOQ
  anchor: jooq
  category: add-on
  logo: /assets/images/logos/jooq.png
  logosmall: /assets/images/logos/jooq-small.png
  description: |
    jOOQ stands for jOOQ Object Oriented Querying (jOOQ). It generates Java code
    from your database, and lets you build type safe SQL queries through its
    fluent API.

    All editions of jOOQ since the 3.19 release include support for Trino. The
    level of support depends on the used catalog and connector, and further
    Trino-specific enhancements are in progress.
  links:
    - urltext: Java Object Oriented Querying (JOOQ)
      url: https://www.jooq.org/
    - urltext: jOOQ 3.19 release notes
      url: https://www.jooq.org/notes
- name: Jupy SQL
  anchor: jupy-sql
  category: client
  logo: /assets/images/logos/jupy-sql.png
  logosmall: /assets/images/logos/jupy-sql-small.png
  description: |
    JupySQL allows you to run SQL and plot large datasets in Jupyter a `%sql`,
    %%sql, and %sqlplot magics. JupySQL is compatible with all major databases,
    data warehouses, embedded engines, and of course also Trino.
  links:
    - urltext: Jupy SQL
      url: https://jupysql.ploomber.io/
    - urltext: Trino tutorial
      url: https://jupysql.ploomber.io/en/latest/integrations/trinodb.html
- name: Kubernetes
  anchor: kubernetes
  category: add-on
  logo: /assets/images/logos/kubernetes.png
  logosmall: /assets/images/logos/kubernetes-small.png
  description: |
    Trino is commonly deployed on the Kubernetes platform. Use the Docker
    container directly or with the Helm chart for your deployment.
  links:
    - urltext: Kubernetes
      url: https://kubernetes.io/
    - urltext: Trino Docker container documentation
      url: https://trino.io/docs/current/installation/containers.html
    - urltext: Trino Helm charts documentation
      url: https://trino.io/docs/current/installation/kubernetes.html
- name: Looker
  anchor: looker
  category: client
  logo: /assets/images/logos/looker.png
  logosmall: /assets/images/logos/looker-small.png
  description: |
    Looker offers a unified business intelligence platform on Google Cloud. It
    is self-service and governance enabled, and can be embedded in your
    solution.
  links:
    - urltext: Looker
      url: https://cloud.google.com/looker
    - urltext: Looker and Trino user guide
      url: https://cloud.google.com/looker/docs/db-config-prestodb-and-trino
- name: MariaDB
  anchor: mariadb
  category: data-source
  logo: /assets/images/logos/mariadb.png
  logosmall: /assets/images/logos/mariadb-small.png
  description: |
    MariaDB Server is one of the most popular open source relational databases.
    It’s made by the original developers of MySQL and guaranteed to stay open
    source. It is part of most cloud offerings and the default in most Linux
    distributions.

    Use a MariaDB database as a data source in Trino by configuring a catalog
    with the MariaDB connector.
  links:
    - urltext: MariaDB
      url: https://mariadb.org/
    - urltext: MariaDB connector documentation
      url: https://trino.io/docs/current/connector/mariadb.html
- name: Metabase
  anchor: metabase
  category: client
  logo: /assets/images/logos/metabase.png
  logosmall: /assets/images/logos/metabase-small.png
  description: |
    Metabase is an open source web based business intelligence platform. You can
    use Metabase to ask questions about your data, or embed Metabase in your app
    to let your customers explore their data on their own. More information is
    available in the driver project repository and the user guide.
  links:
    - urltext: Metabase
      url: https://www.metabase.com/
    - urltext: Metabase driver user guide
      url: https://docs.starburst.io/data-consumer/clients/metabase.html
    - urltext: Metabase driver
      url: https://github.com/starburstdata/metabase-driver
    - urltext: Interview about Metabase from Trino Community Broadcast 44
      url: https://trino.io/episodes/44.html
- name: Microsoft SQL Server
  anchor: sql-server
  category: data-source
  logo: /assets/images/logos/microsoft-sql-server.png
  logosmall: /assets/images/logos/microsoft-sql-server-small.png
  description: |
    Microsoft SQL Server is a proprietary relational database management system
    developed by Microsoft. Microsoft provides different editions of Microsoft
    SQL Server, aimed at different audiences and for workloads ranging from
    small single-machine applications to large Internet-facing applications with
    many concurrent users.

    Use a Microsoft SQL Server database as a data source in Trino by configuring
    a catalog with the SQL Server connector.
  links:
    - urltext: Microsoft SQL Server
      url: https://www.microsoft.com/sql-server
    - urltext: SQL Server connector documentation
      url: https://trino.io/docs/current/connector/sqlserver.html
- name: Microstrategy
  anchor: microstrategy
  category: client
  logo: /assets/images/logos/microstrategy.png
  logosmall: /assets/images/logos/microstrategy-small.png
  description: |
    MicroStrategy is a business intelligence tool that enables you to build up
    platforms that provide real-time data monitoring and can be accessed and
    controlled over any mobile device upon creation. It provides modern
    analytics on an open, comprehensive enterprise platform, and allows users to
    overlay actionable enterprise data on popular business applications to help
    users make smarter, faster decisions.
  links:
    - urltext: Microstrategy
      url: https://www.microstrategy.com/en
    - urltext: Microstrategy with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/microstrategy.html
- name: Minitrino
  anchor: minitrino
  category: add-on
  logo: /assets/images/logos/minitrino.png
  logosmall: /assets/images/logos/minitrino-small.png
  description: |
    Minitrino is a command line tool that makes it easy to run modular Trino
    environments locally. It uses a collection of Docker images to deploy
    various containers alongside Trino, including data sources, security
    integrations, and administration tools.
  links:
    - urltext: Minitrino
      url: https://github.com/jefflester/minitrino
- name: Mitzu
  anchor: mitzu
  category: client
  logo: /assets/images/logos/mitzu.png
  logosmall: /assets/images/logos/mitzu-small.png
  description: |
    Mitzu is a warehouse-native product analytics platform that revolutionizes
    how companies leverage their product usage data in the data lake.

    By directly connecting to Trino, Mitzu eliminates the need for traditional
    reverse ETL processes to 3rd party applications such as Amplitude or
    Mixpanel. Mitzu enables real-time self-served product analytics on top of
    the existing data infrastructure with generated SQL queries.
  links:
    - urltext: Mitzu
      url: https://www.mitzu.io/
    - urltext: Setup for Trino integration to Mitzu
      url: https://docs.mitzu.io/warehouse-integrations/trino-presto
    - urltext: Using Mitzu With Trino blog post
      url: https://www.mitzu.io/post/using-mitzu-with-trino-presto
- name: Mode
  anchor: mode
  category: client
  logo: /assets/images/logos/mode.png
  logosmall: /assets/images/logos/mode-small.png
  description: |
    Mode is the modern business intelligence platform that unites data teams
    with business teams to build analytics that drive business outcomes.
  links:
    - urltext: Mode
      url: https://www.mode.com/
    - urltext: Mode and Trino integration guide
      url: https://mode.com/integrations/trino/
- name: MongoDB
  anchor: mongodb
  category: data-source
  logo: /assets/images/logos/mongodb.png
  logosmall: /assets/images/logos/mongodb-small.png
  description: |
    MongoDB is a source-available cross-platform document-oriented database
    program. Classified as a NoSQL database program, MongoDB uses JSON-like
    documents with optional schemas.

    Use a MongoDB database as a data source in Trino by configuring a catalog
    with the MongoDB connector.
  links:
    - urltext: MongoDB
      url: https://www.mongodb.com/
    - urltext: MongoDB connector documentation
      url: https://trino.io/docs/current/connector/mongodb.html
- name: MySQL
  anchor: mysql
  category: data-source
  logo: /assets/images/logos/mysql.png
  logosmall: /assets/images/logos/mysql-small.png
  description: |
    MySQL is the world's most popular open source relational database management
    system (RDBMS).

    Use a MySQL database as a data source in Trino by configuring a catalog with
    the MySQL connector.
  links:
    - urltext: MySQL
      url: https://www.mysql.com/
    - urltext: MySQL connector documentation
      url: https://trino.io/docs/current/connector/mysql.html
- name: ODBC
  anchor: Odbc
  category: client
  logo: /assets/images/logos/odbc.png
  logosmall: /assets/images/logos/odbc-small.png
  description: |
    Open Database Connectivity (ODBC) enables applications to connect and query
    databases. Use an ODBC driver with your own custom application, or with any
    other application that supports ODBC. ODBC drivers for Trino are available
    from Magnitude. Starburst customers receive an ODBC driver suitable for
    Starburst Enterprise and Starburst Galaxy.
  links:
    - urltext: Magnitiude ODBC driver
      url: https://www.magnitude.com/drivers/trino-odbc-jdbc
    - urltext: Starburst ODBC driver
      url: https://docs.starburst.io/data-consumer/clients/odbc.html
- name: OpenAPI
  anchor: openapi
  category: data-source
  logo: /assets/images/logos/openapi.png
  logosmall: /assets/images/logos/openapi-small.png
  description: |
    OpenAPI is a specification language for REST APIs that provides a
    standardized means to define your API.

    Use any REST API that publishes an OpenAPI specification as a data source in
    Trino by configuring a catalog with the OpenAPI connector, and avoid having
    to generate a client.
  links:
    - urltext: OpenAPI
      url: https://www.openapis.org/
    - urltext: Trino OpenAPI connector
      url: https://github.com/nineinchnick/trino-openapi
- name: Open Policy Agent
  anchor: opa
  category: add-on
  logo: /assets/images/logos/opa.png
  logosmall: /assets/images/logos/opa-small.png
  description: |
    Open Policy Agent (OPA) is a system for policy-based control for cloud
    native environments. It enables flexible, fine-grained control for
    administrators across many systems and applications.

    The Trino plugin enables the use of Open Policy Agent (OPA) as authorization
    engine for access control to catalogs, schemas, tables, and other objects in
    Trino. Policies are defined in OPA, and Trino checks access control
    privileges in OPA.
  links:
    - urltext: Open Policy Agent
      url: https://www.openpolicyagent.org/
    - urltext: Open Policy Agent access control documentation
      url: https://trino.io/docs/current/security/opa-access-control.html
    - urltext: Open Policy Agent for Trino arrvived
      url: http://trino.io/blog/2024/02/06/opa-arrived.html
- name: OpenSearch
  anchor: opensearch
  category: data-source
  logo: /assets/images/logos/opensearch.png
  logosmall: /assets/images/logos/opensearch-small.png
  description: |
    OpenSearch is a scalable, flexible, and extensible open-source software
    suite for search, analytics, and observability applications. OpenSearch
    offers a vendor-agnostic toolset you can use to build secure,
    high-performance, cost-efficient applications. OpenSearch includes a data
    store and search engine, a visualization and user interface, and a library
    of plugins you can use to tailor your tools to your requirements.

    Use an OpenSearch index as a data source in Trino by configuring a
    catalog with the Elasticsearch connector.
  links:
    - urltext: OpenSearch
      url: https://opensearch.org/
    - urltext: Elasticsearch connector documentation
      url: https://trino.io/docs/current/connector/elasticsearch.html
- name: Oracle
  anchor: oracle
  category: data-source
  logo: /assets/images/logos/oracle.png
  logosmall: /assets/images/logos/oracle-small.png
  description: |
    Oracle database services and products offer customers cost-optimized and
    high-performance versions of Oracle Database, the world's leading converged,
    multi-model database management system.

    Use an Oracle database as a data source in Trino by configuring a catalog
    with the Oracle connector.
  links:
    - urltext: Oracle
      url: https://www.oracle.com/database/
    - urltext: Oracle connector documentation
      url: https://trino.io/docs/current/connector/oracle.html
- name: PopSQL
  anchor: popsql
  category: client
  logo: /assets/images/logos/popsql.png
  logosmall: /assets/images/logos/popsql-small.png
  description: |
    PopSQL is a collaborative SQL editor for your team to write queries,
    visualize data, and share your results.
  links:
    - urltext: PopSQL
      url: https://popsql.com/
    - urltext: Connecting to Trino
      url: https://docs.popsql.com/docs/connecting-to-trino
- name: PostgreSQL
  anchor: postgresql
  category: data-source
  logo: /assets/images/logos/postgresql.png
  logosmall: /assets/images/logos/postgresql-small.png
  description: |
    PostgreSQL is the world's most advanced open source relational database.
    PostgreSQL is a powerful system with over 35 years of active development
    that has earned it a strong reputation for reliability, feature robustness,
    and performance.

    Use a PostgreSQL database as a data source in Trino by configuring a catalog
    with the PostgreSQL connector.
  links:
    - urltext: PostgreSQL
      url: https://postgresql.org/
    - urltext: PostgreSQL connector documentation
      url: https://trino.io/docs/current/connector/postgresql.html
- name: Prometheus
  anchor: prometheus
  category: data-source
  logo: /assets/images/logos/prometheus.png
  logosmall: /assets/images/logos/prometheus-small.png
  description: |
    Prometheus is an open source systems monitoring and alerting toolkit with a
    very active developer and user community. Prometheus collects and stores its
    metrics as time series data, i.e. metrics information is stored with the
    timestamp at which it was recorded, alongside optional key-value pairs
    called labels.

    Use a Prometheus database as a data source in Trino by configuring a catalog
    with the Prometheus connector.
  links:
    - urltext: Prometheus
      url: https://prometheus.io/docs/introduction/overview/
    - urltext: Prometheus connector documentation
      url: https://trino.io/docs/current/connector/prometheus.html
- name: Python
  anchor: python
  category: client
  logo: /assets/images/logos/python.png
  logosmall: /assets/images/logos/python-small.png
  description: |
    Python is a programming language that lets you work quickly and integrate
    systems more effectively. Use the Trino Python Client to connect a Python
    script or application to a Trino cluster and receive the results of the
    submitted queries.
  links:
    - urltext: Python
      url: https://www.python.org/
    - urltext: trino-python-client
      url: https://github.com/trinodb/trino-python-client
- name: Querybook
  anchor: querybook
  category: client
  logo: /assets/images/logos/querybook.png
  logosmall: /assets/images/logos/querybook-small.png
  description: |
    Querybook is a browser-based data analysis tool that turns SQL queries into
    natural language reports and graphs called DataDocs. Querybook’s core focus
    is to make composing queries, creating analyses, and collaborating with
    others as simple as possible.
  links:
    - urltext: Querybook
      url: https://www.querybook.org/
    - urltext: Querybook with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/querybook.html
- name: Quix
  anchor: quix
  category: client
  logo: /assets/images/logos/quix.png
  logosmall: /assets/images/logos/quix-small.png
  description: |
    Quix is a multi-user, easy-to-use notebook manager.By utilizing Trino it
    provides unified access to multiple data sources and effectively acts as a
    shared space for your company's BI insights and know-how.
  links:
    - urltext: Quix
      url: https://wix-incubator.github.io/quix/
    - urltext: Documentation for Trino users
      url: https://wix-incubator.github.io/quix/docs/presto
- name: R
  anchor: r
  category: client
  logo: /assets/images/logos/r.png
  logosmall: /assets/images/logos/r-small.png
  description: |
    R is a free software environment for statistical computing and graphics.
    RPresto is a DBI-based adapter for the open source distributed SQL query
    engines Presto and Trino for running interactive analytic queries.
  links:
    - urltext: R
      url: https://www.r-project.org/
    - urltext: RPresto
      url: https://github.com/prestodb/RPresto
- name: Redash
  anchor: redash
  category: client
  logo: /assets/images/logos/redash.png
  logosmall: /assets/images/logos/redash-small.png
  description: |
    Redash is a take on freeing the data within our company in a way that will
    better fit our culture and usage patterns. It has Trino support as well as
    other backends, and offers a query editor with syntax highlighting and
    completion, and creating visualizations and dashboards from query results.
  links:
    - urltext: Redash
      url: https://redash.io/
- name: Redis
  anchor: redis
  category: data-source
  logo: /assets/images/logos/redis.png
  logosmall: /assets/images/logos/redis-small.png
  description: |
    Redis is an open source, in-memory data store used by millions of developers
    as a database, cache, streaming engine, and message broker.

    Use a Redis data store as a data source in Trino by configuring a catalog
    with the Redis connector.
  links:
    - urltext: Redis
      url: https://redis.io/
    - urltext: MySQL connector documentation
      url: https://trino.io/docs/current/connector/redis.html
- name: Ruby
  anchor: ruby
  category: client
  logo: /assets/images/logos/ruby.png
  logosmall: /assets/images/logos/ruby-small.png
  description: |
    Ruby is a dynamic, open source programming language with a focus on
    simplicity and productivity. Use the Trino Ruby client library to connect a
    Ruby script or application to a Trino cluster and receive the results of the
    submitted queries.
  links:
    - urltext: Ruby
      url: https://www.ruby-lang.org/en/
    - urltext: trino-client-ruby
      url: https://github.com/treasure-data/trino-client-ruby
- name: Rust
  anchor: rust
  category: client
  logo: /assets/images/logos/rust.png
  logosmall: /assets/images/logos/rust-small.png
  description: |
    Rust is a programming language empowering everyone to build reliable and
    efficient software. Use the Prusto client library to connect a Rust
    application to a Trino cluster and receive the results of the submitted
    queries.
  links:
    - urltext: Rust
      url: https://www.rust-lang.org/
    - urltext: Prusto
      url: https://github.com/nooberfsh/prusto
- name: RudderStack
  anchor: rudderstack
  category: add-on
  logo: /assets/images/logos/rudderstack.png
  logosmall: /assets/images/logos/rudderstack-small.png
  description: |
    RudderStack provides a reverse ETL pipeline that supports Trino as a source. This
    integration makes it easy to sync data from Trino to over 200 destinations so
    every team can use it to drive better business outcomes. The integration
    supports warehouse-based diffing, making it the most performant reverse ETL
    solution for Trino.
  links:
    - urltext: RudderStack
      url: https://www.rudderstack.com/
    - urltext: Reverse ETL with Trino documentation
      url: https://www.rudderstack.com/docs/sources/reverse-etl/trino/
    - urltext: Annnouncement blog post
      url: https://www.rudderstack.com/blog/feature-launch-trino-reverse-etl-source/
- name: SingleStore
  anchor: singlestore
  category: data-source
  logo: /assets/images/logos/singlestore.png
  logosmall: /assets/images/logos/singlestore-small.png
  description: |
    SingleStoreDB is a unified data engine for transactional and analytical
    workloads, used to power fast, real-time analytics and applications.

    Use a SingleStore database as a data source in Trino by configuring a
    catalog with the SingleStore connector.
  links:
    - urltext: SingleStore
      url: https://www.singlestore.com/
    - urltext: SingleStore connector documentation
      url: https://trino.io/docs/current/connector/singlestore.html
- name: SQL Formatter
  anchor: workload-analyzer
  category: add-on
  logo: /assets/images/logos/sql-formatter.png
  logosmall: /assets/images/logos/sql-formatter-small.png
  description: |
    SQL Formatter is a JavaScript library for pretty-printing SQL queries. It
    supports Trino and can be used as library for web applications, as command
    line tool, and with the live demo deployment. The project is also used for
    VS Code and vim extensions.
  links:
    - urltext: SQL Formatter documentation
      url: https://github.com/sql-formatter-org/sql-formatter/blob/master/README.md
    - urltext: SQL Formatter live demo
      url: https://sql-formatter-org.github.io/sql-formatter/
    - urltext: Documentation for supported languages including Trino
      url: https://github.com/sql-formatter-org/sql-formatter/blob/master/docs/language.md
- name: SQuirrel SQL
  anchor: squirrel-sql
  category: client
  logo: /assets/images/logos/squirrel-sql.png
  logosmall: /assets/images/logos/squirrel-sql-small.png
  description: |
    SQuirrel SQL is a Java-based graphical database client that allows you to
    view the structure of your database, browse the data in tables, and issue
    SQL commands. It uses JDBC to allow users to explore and interact with
    databases via a JDBC driver. In addition, it provides an editor that offers
    code completion and syntax highlighting for standard SQL.
  links:
    - urltext: SQuirrel SQL
      url: http://www.squirrelsql.org/
    - urltext: SQuirrel SQL with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/squirrel-sql.html
- name: Tableau
  anchor: tableau
  category: client
  logo: /assets/images/logos/tableau.png
  logosmall: /assets/images/logos/tableau-small.png
  description: |
    Tableau is a visual analytics platform transforming the way we use data to
    solve problems—empowering people and organizations to make the most of their
    data.
  links:
    - urltext: Tableau
      url: http://www.tableau.com/
    - urltext: How to connect Tableau to Trino
      url: https://help.tableau.com/current/pro/desktop/en-us/examples_presto.htm
- name: Testcontainers
  anchor: testcontainers
  category: add-on
  logo: /assets/images/logos/testcontainers.png
  logosmall: /assets/images/logos/testcontainers-small.png
  description: |
    Testcontainers is an open source framework for providing throwaway,
    lightweight instances of databases, message brokers, web browsers, or just
    about anything that can run in a Docker container.

    Use the Trino module in your integration tests and other scenarios.
  links:
    - urltext: Testcontainers
      url: https://testcontainers.com/
    - urltext: Trino module
      url: https://testcontainers.com/modules/trino/
- name: TPC
  anchor: tpc
  category: data-source
  logo: /assets/images/logos/tpc.png
  logosmall: /assets/images/logos/tpc-small.png
  description: |
    TPC is a non-profit corporation focused on developing data-centric benchmark
    standards and disseminating objective, verifiable data to the industry.

    The Trino TPC-H and TPC-DS connectors are data generators that provide the
    benchmark data sets for direct querying or copying into other data sources
    for testing and benchmarking.
  links:
    - urltext: TPC
      url: https://tpc.org/
    - urltext: TPC-DS connector documentation
      url: https://trino.io/docs/current/connector/tpcds.html
    - urltext: TPC-H connector documentation
      url: https://trino.io/docs/current/connector/tpch.html
- name: Trino-lb
  anchor: trino-lb
  category: add-on
  logo: /assets/images/logos/trino-lb.png
  logosmall: /assets/images/logos/trino-lb-small.png
  description: |
    Trino-lb is a load balancer with support for routing, queueing, and auto-scaling
    for multiple Trino clusters.
  links:
    - urltext: Trino-lb
      url: https://github.com/stackabletech/trino-lb
    - urltext: Trino-lb documentation
      url: https://github.com/stackabletech/trino-lb/blob/main/README.md
- name: Trino Gateway
  anchor: trino-gateway
  category: add-on
  logo: /assets/images/logos/trino-gateway.png
  logosmall: /assets/images/logos/trino-gateway-small.png
  description: |
    Trino Gateway is a load balancer, proxy server, and configurable routing
    gateway for multiple Trino clusters. Users can register/de-register
    Trino clusters behind the gateway and connect to it using standard clients.
  links:
    - urltext: Trino Gateway
      url: https://github.com/trinodb/trino-gateway
    - urltext: Trino Gateway documentation
      url: https://github.com/trinodb/trino-gateway/blob/main/README.md
    - urltext: Many clusters and only one gateway at Trino Summit 2023
      url: https://www.youtube.com/watch?v=2qwBcKmQSn0
    - urltext: Announcement blog post
      url: https://trino.io/blog/2023/09/28/trino-gateway
- name: VAST
  anchor: vast
  category: data-source
  logo: /assets/images/logos/vast.png
  logosmall: /assets/images/logos/vast-small.png
  description: |
    VAST is a data platform that includes storage and database services.

    Use a VAST data store as a data source in Trino by configuring a
    catalog with the VAST Trino connector.
  links:
    - urltext: VAST
      url: https://vastdata.com/
    - urltext: VAST Trino connector
      url: https://github.com/vast-data/vast-trino-connector
    - urltext: VAST database catalog at Trino Summit 2023
      url: https://www.youtube.com/watch?v=RutbCY8i22Q
- name: Workload Analyzer
  anchor: workload-analyzer
  category: add-on
  logo: /assets/images/logos/workload-analyzer.png
  logosmall: /assets/images/logos/workload-analyzer-small.png
  description: |
    The Workload Analyzer collects Trino workload statistics, and analyzes them.
    The resulting report provides improved visibility into your analytical
    workloads, and enables cluster performance optimization.
  links:
    - urltext: Workload analyzer
      url: https://github.com/varadaio/presto-workload-analyzer
    - urltext: Installation instructions
      url: https://github.com/varadaio/presto-workload-analyzer/blob/main/INSTALL.md
- name: VSCode
  anchor: vscode
  category: client
  logo: /assets/images/logos/vscode.png
  logosmall: /assets/images/logos/vscode-small.png
  description: |
    Visual Studio Code (VSCode) is a free, open-source editor by Microsoft
    with features such as syntax highlighting, IntelliSense, code navigation,
    and built-in debugging for developers. With extensions it can also work as
    a SQL client.
  links:
    - urltext: Visual Studio Code
      url:  https://code.visualstudio.com/
    - urltext: sqltools-trino-driver
      url: https://github.com/regadas/sqltools-trino-driver
- name: yanagishima
  anchor: yanagishima
  category: client
  logo: /assets/images/logos/yanagishima.png
  logosmall: /assets/images/logos/yanagishima-small.png
  description: |
    yanagishima is a web application for Trino. yanagishima provides the ability
    to execute query, show query, kill query, bookmark query, search table,
    share query/query result, format query, download as CSV/TSV file, insert
    chart, substitute query parameter, and so on.
  links:
    - urltext: yanagishima
      url: https://yanagishima.github.io/yanagishima/
- name: Zing Data
  anchor: zing-data
  category: client
  logo: /assets/images/logos/zing-data.png
  logosmall: /assets/images/logos/zing-data-small.png
  description: |
    Zing Data is a data analysis and collaboration platform with native apps on
    iOS, Android, and the web. Zing makes asking questions of data and
    visualizing answers easy for everybody in your organization. Free for small
    teams, and super-affordable for bigger ones, Zing requires no SQL, no
    desktop, and no instruction manual. Collaborate as easily as chatting, and
    integrate seamlessly with all the data sources you already have.
  links:
    - urltext: Zing Data
      url: https://getzingdata.com/
    - urltext: Set up Trino as a data source
      url: https://docs.getzingdata.com/docs/setting-up-a-data-source/trino_setup/
    - urltext: Zing Data with Trino tutorial
      url: https://docs.starburst.io/data-consumer/clients/zingdata.html
